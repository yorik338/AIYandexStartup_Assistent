# AYVOR AI Assistant - –ü–æ–ª–Ω–∞—è –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

> AI Voice-Operated Resource - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è Windows

![Project Status](https://img.shields.io/badge/status-58%25%20complete-yellow)
![Version](https://img.shields.io/badge/version-1.0.0-blue)
![License](https://img.shields.io/badge/license-MIT-green)

---

## –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–í–≤–µ–¥–µ–Ω–∏–µ –∏ –û–±–∑–æ—Ä](#1-–≤–≤–µ–¥–µ–Ω–∏–µ-–∏-–æ–±–∑–æ—Ä)
2. [–ë—ã—Å—Ç—Ä—ã–π –°—Ç–∞—Ä—Ç](#2-–±—ã—Å—Ç—Ä—ã–π-—Å—Ç–∞—Ä—Ç)
3. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –°–∏—Å—Ç–µ–º—ã](#3-–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞-—Å–∏—Å—Ç–µ–º—ã)
4. [–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã](#4-–∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã)
5. [API Reference](#5-api-reference)
6. [–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è](#6-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è)
7. [–ö–æ–º–∞–Ω–¥—ã](#7-–∫–æ–º–∞–Ω–¥—ã)
8. [–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞](#8-—Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞)
9. [–ü—Ä–∏–º–µ—Ä—ã –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è](#9-–ø—Ä–∏–º–µ—Ä—ã-–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
10. [–†–µ—à–µ–Ω–∏–µ –ü—Ä–æ–±–ª–µ–º](#10-—Ä–µ—à–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º)
11. [–ò—Å—Ç–æ—Ä–∏—è –ò–∑–º–µ–Ω–µ–Ω–∏–π](#11-–∏—Å—Ç–æ—Ä–∏—è-–∏–∑–º–µ–Ω–µ–Ω–∏–π)

---

# 1. –í–≤–µ–¥–µ–Ω–∏–µ –∏ –û–±–∑–æ—Ä

## 1.1 –û –ü—Ä–æ–µ–∫—Ç–µ

**AYVOR (Aurora)** - —ç—Ç–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è Windows, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ø—Ä–∞–≤–ª—è—Ç—å –∫–æ–º–ø—å—é—Ç–µ—Ä–æ–º —Å –ø–æ–º–æ—â—å—é –≥–æ–ª–æ—Å–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ü—Ä–æ–µ–∫—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –¥–ª—è –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç–∏.

### –ö–ª—é—á–µ–≤—ã–µ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **üé§ Wake Word Detection** - –ê–∫—Ç–∏–≤–∞—Ü–∏—è –ø–æ —Ñ—Ä–∞–∑–µ "–ê–≤—Ä–æ—Ä–∞" —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 95%
- **üó£Ô∏è Speech-to-Text** - –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ –Ω–∞ –±–∞–∑–µ Whisper AI (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)
- **üß† Natural Language Understanding** - –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥ —á–µ—Ä–µ–∑ ChatGPT
- **ü™ü Deep Windows Integration** - –ü—Ä—è–º–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Windows API
- **üöÄ Application Management** - –ó–∞–ø—É—Å–∫ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ 100+ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏
- **‚öôÔ∏è System Control** - –ü–æ–ª–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏
- **üîä Voice Feedback** - –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
- **üîí Security First** - Path validation, command whitelisting, rate limiting
- **üì° Offline Wake Word** - –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–æ–π —Ñ—Ä–∞–∑—ã

### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

- **Frontend**: Electron 27.3.11, Vanilla JavaScript, Custom CSS
- **AI Layer**: Python 3.10+, OpenAI Whisper, ChatGPT 4o-mini
- **Backend**: C# 11 (.NET 8.0), ASP.NET Core, Serilog
- **Communication**: HTTP REST, IPC, Child Processes

### –°—Ç–∞—Ç—É—Å –ü—Ä–æ–µ–∫—Ç–∞

**–ó–∞–≤–µ—Ä—à–µ–Ω–æ: 58%**

‚úÖ **–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ**:
- Wake word detection (Whisper AI - 95% accuracy)
- Speech-to-text —á–µ—Ä–µ–∑ Whisper API
- Natural language understanding —á–µ—Ä–µ–∑ ChatGPT
- 15 —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–∞–Ω–¥
- Application scanner –∏ registry (100+ apps)
- Electron Desktop GUI —Å cyberpunk –¥–∏–∑–∞–π–Ω–æ–º
- HTTP bridge –º–µ–∂–¥—É Python –∏ C#
- Command validation –∏ security
- Rate limiting (30 req/s)
- Logging (Serilog)
- System tray integration
- Global hotkey support
- Voice feedback (TTS)

üöß **–í –†–∞–∑—Ä–∞–±–æ—Ç–∫–µ**:
- –õ–æ–∫–∞–ª—å–Ω—ã–π Whisper –¥–ª—è transcription (–∑–∞–º–µ–Ω–∞ API)
- –õ–æ–∫–∞–ª—å–Ω–∞—è LLM –¥–ª—è intent extraction
- Screen analysis (Claude Vision API integration)
- Context-aware commands
- Multi-step workflows

üîÆ **–ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è**:
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤ (English, Ukrainian)
- Mobile companion app
- Cloud sync –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–µ–∫
- Voice customization
- Advanced automation (if-then rules)

## 1.2 –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (–í—ã—Å–æ–∫–∏–π –£—Ä–æ–≤–µ–Ω—å)

```mermaid
graph TB
    User[üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å]

    subgraph "Layer 1: Electron GUI"
        GUI[jarvis-gui<br/>Electron 27.3.11]
        WakeWord[wake_word.py<br/>Whisper Wake Word]
        UI[renderer.js<br/>UI & Voice Controls]
    end

    subgraph "Layer 2: AI Processing"
        Python[ai-python<br/>Python 3.10+]
        Whisper[Whisper AI<br/>Speech-to-Text]
        ChatGPT[ChatGPT 4o-mini<br/>Intent Extraction]
    end

    subgraph "Layer 3: Execution"
        Core[core<br/>ASP.NET Core 8.0]
        WinAPI[Windows APIs<br/>System Integration]
    end

    User -->|"–ê–≤—Ä–æ—Ä–∞, –æ—Ç–∫—Ä–æ–π Chrome"| WakeWord
    WakeWord -->|JSON events| GUI
    GUI -->|Audio bytes| Python
    Python -->|Transcription| Whisper
    Whisper -->|Text| ChatGPT
    ChatGPT -->|JSON command| Core
    Core -->|Execute| WinAPI
    WinAPI -->|Result| Core
    Core -->|HTTP response| Python
    Python -->|Display| GUI
    GUI -->|Voice/Text| User

    style GUI fill:#2d3748,stroke:#4a5568,color:#fff
    style Python fill:#3182ce,stroke:#2c5282,color:#fff
    style Core fill:#38a169,stroke:#2f855a,color:#fff
    style User fill:#e53e3e,stroke:#c53030,color:#fff
```

### –¢—Ä–∏ –°–ª–æ—è –°–∏—Å—Ç–µ–º—ã

**Layer 1: Electron GUI (jarvis-gui/)**
- Desktop –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- Wake word detection (Whisper-based)
- Voice visualization
- Settings management
- System tray integration

**Layer 2: AI Python Layer (ai-python/)**
- Speech-to-text (Whisper API)
- Intent extraction (ChatGPT)
- Command validation
- HTTP bridge –∫ C# core
- Prompt engineering

**Layer 3: C# Core (core/)**
- ASP.NET Core HTTP API
- Windows system actions execution
- Application registry
- Security & validation
- Logging –∏ monitoring

## 1.3 –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –§—É–Ω–∫—Ü–∏–∏

### üöÄ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä—ã |
|---------|----------|---------|
| **open_app** | –û—Ç–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π –ø–æ –∏–º–µ–Ω–∏ | "–æ—Ç–∫—Ä–æ–π Chrome", "–∑–∞–ø—É—Å—Ç–∏ Discord" |
| **run_exe** | –ó–∞–ø—É—Å–∫ .exe —Ñ–∞–π–ª–æ–≤ –ø–æ –ø—É—Ç–∏ | "–∑–∞–ø—É—Å—Ç–∏ C:\\Apps\\tool.exe" |
| **scan_applications** | –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≥—Ä–∞–º–º | "–ø—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è" |
| **list_applications** | –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π | "–ø–æ–∫–∞–∂–∏ –≤—Å–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è" |

### üìÅ –§–∞–π–ª–æ–≤–∞—è –°–∏—Å—Ç–µ–º–∞

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä—ã |
|---------|----------|---------|
| **search_files** | –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ Documents/Desktop | "–Ω–∞–π–¥–∏ —Ñ–∞–π–ª –æ—Ç—á–µ—Ç" |
| **create_folder** | –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–∫–∏ | "—Å–æ–∑–¥–∞–π –ø–∞–ø–∫—É Projects" |
| **delete_folder** | –£–¥–∞–ª–µ–Ω–∏–µ –ø–∞–ø–∫–∏ | "—É–¥–∞–ª–∏ –ø–∞–ø–∫—É Temp" |
| **move_file** | –ü–µ—Ä–µ–º–µ—â–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ | "–ø–µ—Ä–µ–º–µ—Å—Ç–∏ file.txt –≤ Documents" |
| **copy_file** | –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ | "—Å–∫–æ–ø–∏—Ä—É–π image.png –Ω–∞ Desktop" |

### üéõÔ∏è –°–∏—Å—Ç–µ–º–Ω–æ–µ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä—ã |
|---------|----------|---------|
| **show_desktop** | –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª | "–ø–æ–∫–∞–∂–∏ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª" |
| **screenshot** | –°–Ω–∏–º–æ–∫ —ç–∫—Ä–∞–Ω–∞ | "—Å–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç" |
| **mute** | –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å mute | "–≤—ã–∫–ª—é—á–∏ –∑–≤—É–∫" |
| **set_volume** | –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≥—Ä–æ–º–∫–æ—Å—Ç—å 0-100% | "–≥—Ä–æ–º–∫–æ—Å—Ç—å 50" |
| **capture_window** | –°–∫—Ä–∏–Ω—à–æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ | "—Å–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω –æ–∫–Ω–∞ Chrome" |
| **record_audio** | –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ | "–∑–∞–ø–∏—à–∏ 10 —Å–µ–∫—É–Ω–¥ –∞—É–¥–∏–æ" |

### üí¨ –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –§—É–Ω–∫—Ü–∏–∏

| –§—É–Ω–∫—Ü–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | –ü—Ä–∏–º–µ—Ä—ã |
|---------|----------|---------|
| **system_status** | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ | "–ø–æ–∫–∞–∂–∏ —Å—Ç–∞—Ç—É—Å" |
| **answer_question** | –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ ChatGPT | "—Å–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2 + 2?" |

---

# 2. –ë—ã—Å—Ç—Ä—ã–π –°—Ç–∞—Ä—Ç

## 2.1 –°–∏—Å—Ç–µ–º–Ω—ã–µ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è –°–∏—Å—Ç–µ–º–∞
- **Windows 10** (–≤–µ—Ä—Å–∏—è 1809 –∏–ª–∏ –Ω–æ–≤–µ–µ)
- **Windows 11** (–ª—é–±–∞—è –≤–µ—Ä—Å–∏—è)

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –í–µ—Ä—Å–∏—è | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è | –ì–¥–µ —Å–∫–∞—á–∞—Ç—å |
|-----------|-------------------|---------------|-------------|
| **Python** | 3.10 | 3.11+ | [python.org](https://www.python.org/downloads/) |
| **.NET SDK** | 8.0 | 8.0+ | [dotnet.microsoft.com](https://dotnet.microsoft.com/download/dotnet/8.0) |
| **Node.js** | 18.0 | 20.0+ | [nodejs.org](https://nodejs.org/) |
| **Git** | 2.30+ | Latest | [git-scm.com](https://git-scm.com/) |

### API –ö–ª—é—á–∏

- **OpenAI API Key** (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
  - –ü–æ–ª—É—á–∏—Ç—å: [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
  - –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è Speech-to-Text (Whisper) –∏ ChatGPT
  - –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$0.006 –∑–∞ –º–∏–Ω—É—Ç—É –∞—É–¥–∏–æ + ~$0.0001 –∑–∞ –∫–æ–º–∞–Ω–¥—É

### –°–∏—Å—Ç–µ–º–Ω—ã–µ –†–µ—Å—É—Ä—Å—ã

- **RAM**: 4 GB –º–∏–Ω–∏–º—É–º, 8 GB —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
- **Disk**: 2 GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- **Microphone**: –õ—é–±–æ–π USB –∏–ª–∏ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π
- **Internet**: –î–ª—è OpenAI API –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

## 2.2 –£—Å—Ç–∞–Ω–æ–≤–∫–∞

### –®–∞–≥ 1: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
git clone https://github.com/yourusername/AIYandexStartup_Assistent.git
cd AIYandexStartup_Assistent
```

### –®–∞–≥ 2: Python Environment

#### 2.1 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
cd ai-python
pip install -r requirements.txt
```

**–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—ã–µ –ø–∞–∫–µ—Ç—ã**:
```
requests>=2.31.0          # HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è C# bridge
openai>=1.0.0             # OpenAI API (ChatGPT, Whisper)
httpx>=0.25.0             # Async HTTP —Å proxy support
python-dotenv>=1.0.0      # Environment variables
sounddevice>=0.4.6        # Audio recording
numpy>=1.24.0             # Audio processing
vosk>=0.3.45              # Wake word (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –Ω–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
```

#### 2.2 –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Whisper –¥–ª—è Wake Word

```bash
pip install openai-whisper
```

**–ú–æ–¥–µ–ª–∏ Whisper**:
| Model | Size | Latency | Accuracy | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|-------|------|---------|----------|--------------|
| tiny | 39 MB | ~200ms | 70% | ‚ùå –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è |
| base | 74 MB | ~400ms | 85% | ‚úÖ **–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é** |
| small | 244 MB | ~800ms | 90% | ‚úÖ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| medium | 769 MB | ~2s | 95% | ‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–æ |

#### 2.3 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è .env

–°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª `ai-python/.env`:

```env
# –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
OPENAI_API_KEY=sk-proj-YOUR_KEY_HERE

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û
OPENAI_MODEL=gpt-4o-mini
OPENAI_TRANSCRIPTION_MODEL=whisper-1
OPENAI_BASE_URL=https://api.openai.com/v1

# Proxy (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
# OPENAI_PROXY=http://user:pass@proxy:8080

# C# Core endpoint
JARVIS_CORE_ENDPOINT=http://localhost:5055

# Whisper –º–æ–¥–µ–ª—å –¥–ª—è wake word
WHISPER_MODEL=base
```

**–ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å OpenAI API –∫–ª—é—á**:
1. –ó–∞–π–¥–∏—Ç–µ –Ω–∞ [platform.openai.com](https://platform.openai.com/)
2. –ó–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å –∏–ª–∏ –≤–æ–π–¥–∏—Ç–µ
3. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ [API Keys](https://platform.openai.com/api-keys)
4. –ù–∞–∂–º–∏—Ç–µ "Create new secret key"
5. –°–∫–æ–ø–∏—Ä—É–π—Ç–µ –∫–ª—é—á (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å `sk-proj-` –∏–ª–∏ `sk-`)
6. –í—Å—Ç–∞–≤—å—Ç–µ –≤ `.env`

### –®–∞–≥ 3: C# Core

#### 3.1 –ü—Ä–æ–≤–µ—Ä–∫–∞ .NET SDK

```bash
dotnet --version
# –î–æ–ª–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏: 8.0.x
```

–ï—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - —Å–∫–∞—á–∞–π—Ç–µ SDK —Å [dotnet.microsoft.com](https://dotnet.microsoft.com/download/dotnet/8.0)

#### 3.2 –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–∫–µ—Ç–æ–≤

```bash
cd core
dotnet restore
```

**–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—ã–µ NuGet –ø–∞–∫–µ—Ç—ã**:
- Microsoft.AspNetCore.App (8.0)
- Serilog.AspNetCore
- Serilog.Sinks.File
- NAudio (audio recording)
- System.Drawing.Common (screenshots)

#### 3.3 –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

–§–∞–π–ª `core/appsettings.json` (—É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω):

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  "Kestrel": {
    "Endpoints": {
      "Http": {
        "Url": "http://localhost:5055"
      }
    }
  }
}
```

**–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞** (–µ—Å–ª–∏ 5055 –∑–∞–Ω—è—Ç):
```json
"Http": { "Url": "http://localhost:6000" }
```

–ù–µ –∑–∞–±—É–¥—å—Ç–µ –æ–±–Ω–æ–≤–∏—Ç—å `.env`:
```env
JARVIS_CORE_ENDPOINT=http://localhost:6000
```

### –®–∞–≥ 4: Electron GUI

```bash
cd jarvis-gui
npm install
```

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞–∫–µ—Ç—ã**:
- electron@27.3.11
- electron-builder
- –î—Ä—É–≥–∏–µ dependencies –∏–∑ package.json

## 2.3 –ü–µ—Ä–≤—ã–π –ó–∞–ø—É—Å–∫

### –ú–µ—Ç–æ–¥ 1: –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ (2 —Ç–µ—Ä–º–∏–Ω–∞–ª–∞)

**–¢–µ—Ä–º–∏–Ω–∞–ª 1 - C# Core**:
```bash
cd core
dotnet run
```

–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
info: Microsoft.Hosting.Lifetime[14]
      Now listening on: http://localhost:5055
info: Microsoft.Hosting.Lifetime[0]
      Application started. Press Ctrl+C to shutdown.
```

**–¢–µ—Ä–º–∏–Ω–∞–ª 2 - Electron GUI**:
```bash
cd jarvis-gui
npm start
```

–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:
```
> jarvis-gui@1.0.0 start
> electron .

[wake_word.py] Loading Whisper base model...
[wake_word.py] Whisper base model loaded successfully
[wake_word.py] Wake word detection ready. Say '–ê–≤—Ä–æ—Ä–∞'
```

**–ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫**: Whisper base –º–æ–¥–µ–ª—å (~74 MB) –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (1-2 –º–∏–Ω—É—Ç—ã).

### –ú–µ—Ç–æ–¥ 2: Production Build

```bash
cd jarvis-gui
npm run build
# –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: dist/Ayvor Setup 1.0.0.exe
```

## 2.4 –ü–µ—Ä–≤–∞—è –ö–æ–º–∞–Ω–¥–∞

### –ì–æ–ª–æ—Å–æ–≤–∞—è –ö–æ–º–∞–Ω–¥–∞

1. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±–∞ —Å–µ—Ä–≤–∏—Å–∞ –∑–∞–ø—É—â–µ–Ω—ã
2. –û—Ç–∫—Ä–æ–π—Ç–µ Electron GUI
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å: "–°–ª—É—à–∞—é '–ê–≤—Ä–æ—Ä–∞'..."
4. –°–∫–∞–∂–∏—Ç–µ: **"–ê–≤—Ä–æ—Ä–∞, –æ—Ç–∫—Ä–æ–π –±–ª–æ–∫–Ω–æ—Ç"**

**–û–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ**:
```
1. Wake word detected ‚Üí "–ê–≤—Ä–æ—Ä–∞"
2. Voice recording starts
3. Audio ‚Üí Python ‚Üí Whisper transcription
4. Text ‚Üí ChatGPT ‚Üí JSON command
5. C# opens Notepad
6. GUI shows: "Successfully opened Notepad"
```

### –¢–µ–∫—Å—Ç–æ–≤–∞—è –ö–æ–º–∞–Ω–¥–∞

1. –í GUI –Ω–∞–∂–º–∏—Ç–µ –Ω–∞ –ø–æ–ª–µ –≤–≤–æ–¥–∞
2. –í–≤–µ–¥–∏—Ç–µ: `–æ—Ç–∫—Ä–æ–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä`
3. –ù–∞–∂–º–∏—Ç–µ Enter

–†–µ–∑—É–ª—å—Ç–∞—Ç: –ö–∞–ª—å–∫—É–ª—è—Ç–æ—Ä –æ—Ç–∫—Ä–æ–µ—Ç—Å—è.

## 2.5 –ü—Ä–æ–≤–µ—Ä–∫–∞ –£—Å—Ç–∞–Ω–æ–≤–∫–∏

### –¢–µ—Å—Ç 1: C# Health Check

```bash
curl http://localhost:5055/system/status
```

–û—Ç–≤–µ—Ç:
```json
{
  "status": "ok",
  "message": "System is operational"
}
```

### –¢–µ—Å—Ç 2: Python Bridge

```bash
cd ai-python
python test_connection.py
```

–í—ã–≤–æ–¥:
```
‚úÖ C# Core is reachable
‚úÖ System status: ok
‚úÖ Bridge connection successful
```

### –¢–µ—Å—Ç 3: –û—Ç–∫—Ä—ã—Ç–∏–µ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è

```bash
curl -X POST http://localhost:5055/action/execute \
  -H "Content-Type: application/json" \
  -d '{
    "action": "open_app",
    "params": {"application": "notepad"},
    "uuid": "test-123",
    "timestamp": "2025-12-27T10:00:00Z"
  }'
```

–†–µ–∑—É–ª—å—Ç–∞—Ç: Notepad –¥–æ–ª–∂–µ–Ω –æ—Ç–∫—Ä—ã—Ç—å—Å—è.

---

# 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –°–∏—Å—Ç–µ–º—ã

## 3.1 –û–±–∑–æ—Ä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

AYVOR –ø–æ—Å—Ç—Ä–æ–µ–Ω –Ω–∞ **—Ç—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ** (three-tier architecture) —Å —á–µ—Ç–∫–∏–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏:

1. **Presentation Layer** - Electron GUI (JavaScript/HTML/CSS)
2. **Business Logic Layer** - AI Python (NLU, Speech Processing)
3. **Data/Execution Layer** - C# Core (Windows API Integration)

### –ü—Ä–∏–Ω—Ü–∏–ø—ã –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

- **Separation of Concerns** - –ö–∞–∂–¥—ã–π —Å–ª–æ–π –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Å–≤–æ—é –æ–±–ª–∞—Å—Ç—å
- **Loose Coupling** - –°–ª–æ–∏ –æ–±—â–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ —á–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã (HTTP REST, IPC)
- **Modularity** - –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω—è—Ç—å –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö —Å–ª–æ–µ–≤
- **Security by Design** - –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –∫–∞–∂–¥–æ–º —É—Ä–æ–≤–Ω–µ
- **Fail-Safe** - Graceful degradation –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

## 3.2 –î–µ—Ç–∞–ª—å–Ω–∞—è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```mermaid
graph TB
    subgraph "User Interface Layer"
        User[üë§ User]
        ElectronMain[Electron Main Process<br/>main.js]
        ElectronRenderer[Electron Renderer<br/>renderer.js]
        WakeWordPy[Wake Word Service<br/>wake_word.py<br/>Whisper AI]
    end

    subgraph "AI Processing Layer"
        Pipeline[Pipeline<br/>pipeline.py]
        Speech[Speech Module<br/>speech.py<br/>Whisper API]
        NLU[NLU Module<br/>nlu.py<br/>ChatGPT]
        Bridge[HTTP Bridge<br/>bridge_requests.py]
        Schemas[Validation<br/>schemas.py]
    end

    subgraph "Execution Layer"
        AspNetCore[ASP.NET Core 8.0<br/>Program.cs]
        Executor[WindowsActionExecutor<br/>Action Dispatcher]
        Scanner[ApplicationScanner<br/>Registry Manager]
        Capture[WindowCaptureService<br/>Screenshot]
        Audio[MicrophoneRecorder<br/>NAudio]
        Validator[CommandValidator<br/>Security]
    end

    subgraph "Windows OS"
        ProcessAPI[Process API]
        FileAPI[File System API]
        AudioAPI[Audio API]
        ScreenAPI[Screen Capture API]
    end

    User -->|Voice/Text| ElectronRenderer
    ElectronRenderer <-->|IPC| ElectronMain
    ElectronMain -->|spawn| WakeWordPy
    WakeWordPy -->|JSON events| ElectronRenderer
    ElectronRenderer -->|HTTP POST| Pipeline

    Pipeline --> Speech
    Pipeline --> NLU
    Speech --> NLU
    NLU --> Schemas
    Schemas --> Bridge

    Bridge -->|HTTP POST| AspNetCore
    AspNetCore --> Validator
    Validator --> Executor
    Executor --> Scanner
    Executor --> Capture
    Executor --> Audio

    Executor --> ProcessAPI
    Executor --> FileAPI
    Executor --> AudioAPI
    Executor --> ScreenAPI

    ProcessAPI -->|Result| Executor
    FileAPI -->|Result| Executor
    AudioAPI -->|Result| Executor
    ScreenAPI -->|Result| Executor

    Executor -->|Response| AspNetCore
    AspNetCore -->|JSON| Bridge
    Bridge -->|Dict| Pipeline
    Pipeline -->|Result| ElectronRenderer
    ElectronRenderer -->|Display| User

    style ElectronRenderer fill:#2d3748,color:#fff
    style Pipeline fill:#3182ce,color:#fff
    style Executor fill:#38a169,color:#fff
```

## 3.3 Data Flow - Voice Command

–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–æ–º–∞–Ω–¥—ã:

```mermaid
sequenceDiagram
    participant User
    participant WakeWord as wake_word.py
    participant Renderer as renderer.js
    participant Main as main.js
    participant Python as ai-python
    participant Whisper as Whisper API
    participant ChatGPT as ChatGPT API
    participant Core as C# Core
    participant Windows as Windows OS

    User->>WakeWord: –ì–æ–≤–æ—Ä–∏—Ç "–ê–≤—Ä–æ—Ä–∞, –æ—Ç–∫—Ä–æ–π Chrome"

    Note over WakeWord: Continuous listening (3s chunks)
    WakeWord->>WakeWord: Transcribe with Whisper (local)
    WakeWord->>WakeWord: Check for "–∞–≤—Ä–æ—Ä–∞"

    alt Wake word detected
        WakeWord->>Renderer: JSON event: wake_word detected
        Renderer->>Renderer: Start voice recording
        Renderer->>User: Visual feedback (recording...)

        User->>Renderer: Speaks command
        Renderer->>Renderer: Capture audio (sounddevice)

        alt Silence detected
            Renderer->>Python: POST /process_audio (audio bytes)
            Python->>Whisper: Transcribe audio
            Whisper-->>Python: Text: "–æ—Ç–∫—Ä–æ–π Chrome"

            Python->>ChatGPT: Extract intent from text
            ChatGPT-->>Python: JSON: {action: "open_app", params: {application: "chrome"}}

            Python->>Python: Validate command (schemas.py)

            Python->>Core: POST /action/execute
            Core->>Core: Validate action & params
            Core->>Core: Check application registry
            Core->>Windows: Start process (chrome.exe)
            Windows-->>Core: Process started (PID: 12345)
            Core-->>Python: Response: {status: "ok", result: {...}}

            Python-->>Renderer: Success response
            Renderer->>User: Display: "Successfully opened Chrome"
            Renderer->>User: TTS: "–û—Ç–∫—Ä—ã–ª Chrome"
        end
    else Wake word not detected
        WakeWord->>WakeWord: Continue listening
    end
```

## 3.4 Data Flow - Wake Word Detection

```mermaid
flowchart TD
    Start([Start wake_word.py]) --> LoadModel[Load Whisper Model<br/>base/small/medium]
    LoadModel --> InitAudio[Initialize sounddevice<br/>16kHz, mono, int16]
    InitAudio --> StartStream[Start audio stream<br/>BLOCK_SIZE=8000]

    StartStream --> Listen[Listen microphone]
    Listen --> Queue[Add to audio_queue]
    Queue --> Buffer{Buffer >= 3 seconds?}

    Buffer -->|No| Listen
    Buffer -->|Yes| Concat[Concatenate audio chunks]

    Concat --> Convert[Convert int16 ‚Üí float32<br/>Normalize to [-1, 1]]
    Convert --> Transcribe[Whisper.transcribe<br/>language='ru'<br/>beam_size=1]

    Transcribe --> GetText[Extract text]
    GetText --> CheckEmpty{Text empty?}

    CheckEmpty -->|Yes| ClearBuffer[Clear buffer]
    CheckEmpty -->|No| OutputTranscription[Output JSON:<br/>type: transcription]

    OutputTranscription --> CheckWake{Contains wake word?<br/>–∞–≤—Ä–æ—Ä–∞, –∞–≤—Ä–æ—Ä, aurora}

    CheckWake -->|No| KeepOverlap[Keep last 1s for overlap]
    CheckWake -->|Yes| ExtractCommand[Extract command after wake word]

    ExtractCommand --> OutputWake[Output JSON:<br/>type: wake_word<br/>text, wake_word, command]
    OutputWake --> ClearBuffer

    KeepOverlap --> Listen
    ClearBuffer --> Listen

    style LoadModel fill:#ffd700
    style CheckWake fill:#ff6b6b
    style OutputWake fill:#4ecdc4
```

## 3.5 Component Communication

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Electron GUI Process                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Main Process (main.js)                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Window management                                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Tray icon                                             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Global shortcuts                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Config file I/O                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ IPC (contextBridge)                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Renderer Process (renderer.js)                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - UI rendering                                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Voice recording                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Audio visualization                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Settings panel                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ Child Process (spawn)                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  wake_word.py (Python subprocess)                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Whisper AI model                                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Continuous audio stream                               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Wake word detection                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Output: JSON events via stdout                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ HTTP POST (fetch API)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  AI Python Layer (Flask/FastAPI)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  pipeline.py - Main entry point                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ process_text(text, bridge)                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îú‚îÄ process_audio_file(path, bridge)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ process_audio_stream(chunks, bridge)                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  speech.py - Whisper integration                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  transcribe_audio_file() ‚Üí Text                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  nlu.py - Intent extraction                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  IntentExtractor.extract(text) ‚Üí Command                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  schemas.py - Validation                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  validate_command(cmd) ‚Üí Valid/Invalid                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  bridge_requests.py - HTTP Bridge                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  HttpBridge.send_command(cmd) ‚Üí Response                 ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ HTTP POST to localhost:5055
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   C# Core (ASP.NET Core 8.0)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Program.cs - HTTP Server (Kestrel)                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  POST /action/execute ‚Üí CommandRequest                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  CommandValidator - Security layer                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Validate action name                                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Validate required params                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Rate limiting (30 req/s)                              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  WindowsActionExecutor - Action dispatcher               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  switch (action) {                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    case "open_app": OpenApplication()                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    case "screenshot": CaptureScreenshot()                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    case "set_volume": SetSystemVolume()                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ    ...                                                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  }                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Services:                                                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ApplicationScanner (scan drives)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - ApplicationRegistry (cache apps)                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - WindowCaptureService (screenshots)                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - MicrophoneRecorder (NAudio)                            ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ              ‚îÇ                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Windows API Calls:                                       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Process.Start() - –∑–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - File.Copy/Move/Delete - —Ñ–∞–π–ª–æ–≤—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏             ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - SendKeys - –∫–ª–∞–≤–∏–∞—Ç—É—Ä–Ω—ã–π –≤–≤–æ–¥                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - CoreAudioApi - —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–≤—É–∫–æ–º                      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  - Graphics.CopyFromScreen - —Å–∫—Ä–∏–Ω—à–æ—Ç—ã                   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 3.6 Security Architecture

### –£—Ä–æ–≤–Ω–∏ –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

**Level 1: Input Validation (Python)**
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON –∫–æ–º–∞–Ω–¥—ã
- –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
- –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö

**Level 2: Command Whitelisting (C#)**
- –¢–æ–ª—å–∫–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ 15 actions
- –ü—Ä–æ–≤–µ—Ä–∫–∞ required –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
- –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ–º–∞–Ω–¥

**Level 3: Path Validation (C#)**
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –∫ system folders
- Whitelist —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:
  - `%USERPROFILE%\Documents`
  - `%USERPROFILE%\Desktop`
  - `%USERPROFILE%\Downloads`
  - `%USERPROFILE%\Pictures`
- –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞:
  - `C:\Windows\`
  - `C:\Program Files\` (–∫—Ä–æ–º–µ —á—Ç–µ–Ω–∏—è)
  - `C:\ProgramData\`

**Level 4: Process Execution Safety (C#)**
- –¢–æ–ª—å–∫–æ .exe —Ñ–∞–π–ª—ã (–Ω–µ .bat, .cmd, .ps1)
- UseShellExecute = true (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—É—Å–∫)
- –£—Å—Ç–∞–Ω–æ–≤–∫–∞ WorkingDirectory

**Level 5: Rate Limiting (C#)**
- –ú–∞–∫—Å–∏–º—É–º 30 –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
- –ó–∞—â–∏—Ç–∞ –æ—Ç DoS –∞—Ç–∞–∫
- Throttling –ø–æ IP (localhost)

### Security Best Practices

```csharp
// –ü—Ä–∏–º–µ—Ä Path Validation –≤ C#
private bool IsPathAllowed(string path)
{
    var normalizedPath = Path.GetFullPath(path);

    // –ë–ª–æ–∫–∏—Ä—É–µ–º system folders
    var blockedPaths = new[] {
        Environment.GetFolderPath(Environment.SpecialFolder.Windows),
        Environment.GetFolderPath(Environment.SpecialFolder.System),
        "C:\\ProgramData"
    };

    foreach (var blocked in blockedPaths)
    {
        if (normalizedPath.StartsWith(blocked, StringComparison.OrdinalIgnoreCase))
            return false;
    }

    return true;
}
```

---

# 4. –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

## 4.1 Electron GUI (jarvis-gui/)

### 4.1.1 –û–±–∑–æ—Ä

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Desktop UI –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏**:
- Electron 27.3.11
- Vanilla JavaScript (–±–µ–∑ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–æ–≤)
- Custom CSS (cyberpunk theme)
- HTML5

**–û—Å–Ω–æ–≤–Ω—ã–µ –§–∞–π–ª—ã**:
| –§–∞–π–ª | –°—Ç—Ä–æ–∫ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|------|-------|-----------|
| main.js | 543 | Main process, window management, tray |
| renderer.js | 1235 | UI logic, voice recording, settings |
| preload.js | 115 | IPC bridge, context isolation |
| wake_word.py | 186 | Wake word detection (Whisper) |
| index.html | 350 | UI structure |
| styles.css | 800 | Cyberpunk styling |

### 4.1.2 main.js - Main Process

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**:
- –°–æ–∑–¥–∞–Ω–∏–µ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–∫–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
- System tray integration
- Global hotkeys (Ctrl+Shift+Space)
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (—á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å config.json)
- IPC communication —Å renderer

**–ö–ª—é—á–µ–≤—ã–µ –§—É–Ω–∫—Ü–∏–∏**:

```javascript
// –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫–Ω–∞
function createWindow() {
  mainWindow = new BrowserWindow({
    width: 1400,
    height: 900,
    webPreferences: {
      preload: path.join(__dirname, 'preload.js'),
      contextIsolation: true,
      nodeIntegration: false
    }
  });

  mainWindow.loadFile('index.html');
}

// System tray
function createTray() {
  tray = new Tray(trayIcon);
  tray.setContextMenu(Menu.buildFromTemplate([
    { label: 'Show', click: () => mainWindow.show() },
    { label: 'Quit', click: () => app.quit() }
  ]));
}

// Global hotkey
globalShortcut.register('CommandOrControl+Shift+Space', () => {
  mainWindow.webContents.send('toggle-listening');
});

// IPC handlers
ipcMain.handle('get-config', async () => {
  return JSON.parse(fs.readFileSync(configPath, 'utf-8'));
});

ipcMain.handle('save-config', async (event, config) => {
  fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
});
```

### 4.1.3 renderer.js - Renderer Process

**–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏**:
- UI rendering –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
- Voice recording —á–µ—Ä–µ–∑ sounddevice/Web Audio API
- Audio visualization (waveform)
- Wake word process management
- Settings panel
- Command history (localStorage)
- TTS (Speech Synthesis API)

**–ö–ª—é—á–µ–≤–æ–π –ö–æ–¥**:

```javascript
// Wake word process spawning
function startWakeWord() {
  const pythonPath = 'python'; // –ò–ª–∏ –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
  const scriptPath = path.join(__dirname, 'wake_word.py');

  wakeWordProcess = spawn(pythonPath, [scriptPath], {
    env: { ...process.env, WHISPER_MODEL: 'base' }
  });

  wakeWordProcess.stdout.on('data', (data) => {
    const lines = data.toString().split('\n');
    lines.forEach(line => {
      if (!line.trim()) return;

      try {
        const event = JSON.parse(line);
        handleWakeWordEvent(event);
      } catch (err) {
        console.error('Failed to parse wake word event:', err);
      }
    });
  });
}

// Wake word event handler
function handleWakeWordEvent(event) {
  switch (event.type) {
    case 'ready':
      updateWakeWordStatus('–°–ª—É—à–∞—é "–ê–≤—Ä–æ—Ä–∞"...', true);
      break;

    case 'wake_word':
      console.log('Wake word detected:', event.text);
      if (event.command) {
        // –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª –∫–æ–º–∞–Ω–¥—É —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ wake word
        processTextCommand(event.command);
      } else {
        // –¢–æ–ª—å–∫–æ wake word, –Ω–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
        startVoiceRecording();
      }
      break;

    case 'transcription':
      console.log('Transcription:', event.message);
      break;

    case 'error':
      console.error('Wake word error:', event.message);
      updateWakeWordStatus('–û—à–∏–±–∫–∞: ' + event.message, false);
      break;
  }
}

// Voice recording
let mediaRecorder;
let audioChunks = [];

async function startVoiceRecording() {
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorder = new MediaRecorder(stream);

  mediaRecorder.ondataavailable = (event) => {
    audioChunks.push(event.data);
  };

  mediaRecorder.onstop = async () => {
    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
    await sendAudioToPython(audioBlob);
    audioChunks = [];
  };

  mediaRecorder.start();
  updateRecordingStatus(true);

  // Stop after silence detection or max duration
  setTimeout(() => {
    if (mediaRecorder.state === 'recording') {
      mediaRecorder.stop();
    }
  }, 10000); // Max 10 seconds
}

// Send audio to Python
async function sendAudioToPython(audioBlob) {
  const formData = new FormData();
  formData.append('audio', audioBlob);

  try {
    const response = await fetch('http://localhost:8000/process_audio', {
      method: 'POST',
      body: formData
    });

    const result = await response.json();
    displayCommandResult(result);
  } catch (error) {
    console.error('Failed to process audio:', error);
    showError('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞—É–¥–∏–æ');
  }
}

// Text-to-Speech
function speak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.lang = 'ru-RU';
  utterance.rate = 1.0;
  speechSynthesis.speak(utterance);
}
```

### 4.1.4 preload.js - Security Bridge

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –º–æ—Å—Ç –º–µ–∂–¥—É main –∏ renderer –ø—Ä–æ—Ü–µ—Å—Å–∞–º–∏

**Context Isolation**: Renderer –Ω–µ –∏–º–µ–µ—Ç –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ Node.js API

```javascript
const { contextBridge, ipcRenderer } = require('electron');
const { spawn } = require('child_process');
const path = require('path');

// Expose limited API to renderer
contextBridge.exposeInMainWorld('ayvorAPI', {
  // IPC communication
  ipc: {
    send: (channel, data) => {
      const validChannels = ['minimize-to-tray', 'update-tray-status'];
      if (validChannels.includes(channel)) {
        ipcRenderer.send(channel, data);
      }
    },

    invoke: (channel, data) => {
      const validChannels = ['get-config', 'save-config'];
      if (validChannels.includes(channel)) {
        return ipcRenderer.invoke(channel, data);
      }
    },

    on: (channel, callback) => {
      const validChannels = ['start-listening', 'stop-listening', 'toggle-listening', 'app-closing'];
      if (validChannels.includes(channel)) {
        ipcRenderer.on(channel, (event, ...args) => callback(...args));
      }
    }
  },

  // Process spawning (–¥–ª—è wake_word.py)
  process: {
    spawnPythonScript: (scriptName, options = {}) => {
      const pythonPath = options.pythonPath || 'python';
      const scriptPath = path.join(__dirname, scriptName);

      const proc = spawn(pythonPath, [scriptPath], {
        env: { ...process.env, ...options.env }
      });

      return {
        onStdout: (callback) => proc.stdout.on('data', callback),
        onStderr: (callback) => proc.stderr.on('data', callback),
        onError: (callback) => proc.on('error', callback),
        onClose: (callback) => proc.on('close', callback),
        kill: () => proc.kill()
      };
    }
  },

  // Path utilities
  path: {
    join: (...args) => path.join(...args),
    dirname: __dirname
  }
});
```

### 4.1.5 wake_word.py - Wake Word Detection

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏–µ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ñ—Ä–∞–∑—ã "–ê–≤—Ä–æ—Ä–∞"

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏**:
- OpenAI Whisper (–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)
- sounddevice (audio capture)
- NumPy (audio processing)

**–ê–ª–≥–æ—Ä–∏—Ç–º**:
1. –ó–∞–≥—Ä—É–∑–∫–∞ Whisper –º–æ–¥–µ–ª–∏ (base/small/medium)
2. –û—Ç–∫—Ä—ã—Ç–∏–µ audio stream (16kHz, mono, int16)
3. –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –∑–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ —á–∞–Ω–∫–∞–º–∏ –ø–æ 3 —Å–µ–∫—É–Ω–¥—ã
4. –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞ —á–µ—Ä–µ–∑ Whisper
5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è wake word –≤ —Ç–µ–∫—Å—Ç–µ
6. –ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ - –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –ø–æ—Å–ª–µ wake word
7. –û—Ç–ø—Ä–∞–≤–∫–∞ JSON —Å–æ–±—ã—Ç–∏—è –≤ stdout

**–ö–æ–¥**:

```python
#!/usr/bin/env python3
"""
Wake Word Detection Service using Whisper
Listens for "–ê–≤—Ä–æ—Ä–∞" wake word and outputs JSON events to stdout
"""

import sys
import os
import json
import queue
import signal
import numpy as np
from io import BytesIO

# Set encoding for stdout
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

try:
    import sounddevice as sd
except ImportError:
    print(json.dumps({"type": "error", "message": "sounddevice not installed"}))
    sys.exit(1)

try:
    import whisper
except ImportError:
    print(json.dumps({"type": "error", "message": "whisper not installed. Run: pip install openai-whisper"}))
    sys.exit(1)

# Wake words to detect
WAKE_WORDS = ['–∞–≤—Ä–æ—Ä–∞', '–∞–≤—Ä–æ—Ä', '–∞–≤—Ä–æ—Ä—ã', 'aurora', '—ç–π –∞–≤—Ä–æ—Ä–∞', '–ø—Ä–∏–≤–µ—Ç –∞–≤—Ä–æ—Ä–∞']

# Audio settings
SAMPLE_RATE = 16000
BLOCK_SIZE = 8000
CHUNK_DURATION = 3  # seconds

# Whisper model
WHISPER_MODEL = os.getenv('WHISPER_MODEL', 'base')

# Global state
audio_queue = queue.Queue()
audio_buffer = []
running = True
whisper_model = None


def signal_handler(sig, frame):
    """Handle shutdown signals"""
    global running
    running = False
    output_event("shutdown", "Wake word service stopped")
    sys.exit(0)


def output_event(event_type: str, message: str = "", data: dict = None):
    """Output JSON event to stdout"""
    event = {
        "type": event_type,
        "message": message
    }
    if data:
        event.update(data)
    print(json.dumps(event, ensure_ascii=False), flush=True)


def audio_callback(indata, frames, time, status):
    """Callback for audio stream"""
    if status:
        output_event("audio_error", str(status))
    audio_queue.put(bytes(indata))


def check_wake_word(text: str) -> tuple[bool, str, str]:
    """
    Check if text contains wake word
    Returns: (detected, wake_word, command_after)
    """
    text_lower = text.lower().strip()

    for wake_word in WAKE_WORDS:
        if wake_word in text_lower:
            # Extract command after wake word
            parts = text_lower.split(wake_word, 1)
            command_after = parts[1].strip() if len(parts) > 1 else ""
            return True, wake_word, command_after

    return False, "", ""


def main():
    global running, whisper_model, audio_buffer

    # Setup signal handlers
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Initialize Whisper model
    output_event("status", f"Loading Whisper {WHISPER_MODEL} model (first time may take a while)...")
    try:
        whisper_model = whisper.load_model(WHISPER_MODEL)
        output_event("status", f"Whisper {WHISPER_MODEL} model loaded successfully")
    except Exception as e:
        output_event("error", f"Failed to load Whisper model: {e}")
        sys.exit(1)

    output_event("ready", "Wake word detection ready. Say '–ê–≤—Ä–æ—Ä–∞'")

    # Calculate samples per chunk
    samples_per_chunk = SAMPLE_RATE * CHUNK_DURATION

    # Start audio stream
    try:
        with sd.RawInputStream(
            samplerate=SAMPLE_RATE,
            blocksize=BLOCK_SIZE,
            dtype='int16',
            channels=1,
            callback=audio_callback
        ):
            while running:
                try:
                    data = audio_queue.get(timeout=0.5)
                except queue.Empty:
                    continue

                # Add to buffer
                audio_buffer.append(np.frombuffer(data, dtype=np.int16))

                # Check if we have enough audio
                total_samples = sum(len(chunk) for chunk in audio_buffer)
                if total_samples >= samples_per_chunk:
                    # Concatenate and convert to float32
                    audio_array = np.concatenate(audio_buffer)
                    audio_float = audio_array.astype(np.float32) / 32768.0

                    # Transcribe with Whisper
                    try:
                        result = whisper_model.transcribe(
                            audio_float,
                            language='ru',
                            fp16=False,  # CPU mode
                            beam_size=1,  # Faster inference
                            best_of=1
                        )
                        text = result.get('text', '').strip()

                        if text:
                            output_event("transcription", text)

                            # Check for wake word
                            detected, wake_word, command = check_wake_word(text)
                            if detected:
                                output_event("wake_word", f"Detected: {text}", {
                                    "text": text,
                                    "wake_word": wake_word,
                                    "command": command
                                })
                                # Clear buffer after detection
                                audio_buffer = []
                            else:
                                # Keep last second for overlap
                                samples_to_keep = SAMPLE_RATE
                                audio_buffer = [audio_array[-samples_to_keep:]]
                        else:
                            # Clear buffer if no speech detected
                            audio_buffer = []

                    except Exception as e:
                        output_event("error", f"Transcription error: {e}")
                        audio_buffer = []

    except sd.PortAudioError as e:
        output_event("error", f"Audio device error: {e}")
        sys.exit(1)
    except Exception as e:
        output_event("error", f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
```

**JSON Events**:

```json
// Ready
{"type": "ready", "message": "Wake word detection ready. Say '–ê–≤—Ä–æ—Ä–∞'"}

// Transcription
{"type": "transcription", "message": "–ø—Ä–∏–≤–µ—Ç –∫–∞–∫ –¥–µ–ª–∞"}

// Wake word detected
{
  "type": "wake_word",
  "message": "Detected: –ê–≤—Ä–æ—Ä–∞ –æ—Ç–∫—Ä–æ–π Chrome",
  "text": "–ê–≤—Ä–æ—Ä–∞ –æ—Ç–∫—Ä–æ–π Chrome",
  "wake_word": "–∞–≤—Ä–æ—Ä–∞",
  "command": "–æ—Ç–∫—Ä–æ–π Chrome"
}

// Error
{"type": "error", "message": "Transcription error: ..."}
```

---

## 4.2 AI Python Layer (ai-python/)

### 4.2.1 –û–±–∑–æ—Ä

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ bridge –º–µ–∂–¥—É Electron –∏ C#

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞** (10 –º–æ–¥—É–ª–µ–π, 974 —Å—Ç—Ä–æ–∫–∏):
```
ai-python/
‚îú‚îÄ‚îÄ ai_assistant/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Package init
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py           # Orchestration (72 lines)
‚îÇ   ‚îú‚îÄ‚îÄ nlu.py                # Intent extraction (58 lines)
‚îÇ   ‚îú‚îÄ‚îÄ speech.py             # Whisper integration (163 lines)
‚îÇ   ‚îú‚îÄ‚îÄ llm.py                # ChatGPT backends (120 lines)
‚îÇ   ‚îú‚îÄ‚îÄ bridge_requests.py    # HTTP client (110 lines)
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py            # Validation (88 lines)
‚îÇ   ‚îú‚îÄ‚îÄ prompts.py            # Prompt engineering (148 lines)
‚îÇ   ‚îî‚îÄ‚îÄ openai_client.py      # OpenAI client (100 lines)
‚îú‚îÄ‚îÄ main.py                   # Demo entry point
‚îú‚îÄ‚îÄ test_connection.py        # Bridge test
‚îú‚îÄ‚îÄ requirements.txt          # Dependencies
‚îî‚îÄ‚îÄ .env                      # Configuration
```

**Dependencies**:
```txt
requests>=2.31.0          # HTTP –∫–ª–∏–µ–Ω—Ç
openai>=1.0.0             # OpenAI API
httpx>=0.25.0             # Async HTTP —Å proxy
python-dotenv>=1.0.0      # Environment variables
sounddevice>=0.4.6        # Audio capture
numpy>=1.24.0             # Audio processing
vosk>=0.3.45              # Installed but not used
```

### 4.2.2 pipeline.py - Orchestration

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: End-to-end –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–º–∞–Ω–¥

**–§—É–Ω–∫—Ü–∏–∏**:

```python
"""Main pipeline for processing user input."""

from pathlib import Path
from typing import Optional, Iterable

from .speech import transcribe_audio_file, transcribe_audio_stream
from .nlu import IntentExtractor
from .bridge_requests import HttpBridge
from .llm import PromptSender


def process_text(
    text: str,
    bridge: HttpBridge,
    *,
    sender: Optional[PromptSender] = None
) -> Optional[dict]:
    """
    Process a text query and forward a validated command to the C# bridge.

    Args:
        text: User's natural language command
        bridge: Bridge instance for C# communication
        sender: Optional custom LLM backend (for testing)

    Returns:
        dict: C# response or None if bridge failed
        Format: {"status": "ok"|"error", "result": {...}, "error": str|None}

    Example:
        >>> bridge = HttpBridge("http://localhost:5055")
        >>> result = process_text("–æ—Ç–∫—Ä–æ–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä", bridge)
        >>> print(result)
        {"status": "ok", "result": {"message": "Opened Calculator"}, ...}
    """
    extractor = IntentExtractor(sender=sender)
    command = extractor.extract(text)

    if not command:
        # Failed to extract valid command, generate answer instead
        from .prompts import build_answer_prompt
        from .llm import PromptSender

        sender = sender or PromptSender()
        answer_prompt = build_answer_prompt(text)
        answer = sender.send_prompt(answer_prompt)

        # Send answer_question action to C#
        from .schemas import Command
        answer_cmd = Command(
            action="answer_question",
            params={"answer": answer, "question": text},
            uuid="answer-" + str(hash(text)),
            timestamp=_get_timestamp()
        )
        return bridge.send_command(answer_cmd)

    # Valid command, send to C# bridge
    return bridge.send_command(command)


def process_audio_file(
    audio_path: Path,
    bridge: HttpBridge,
    *,
    sender: Optional[PromptSender] = None
) -> Optional[dict]:
    """
    Transcribe audio file using Whisper, then process as text.

    Args:
        audio_path: Path to audio file (WAV, MP3, etc.)
        bridge: Bridge instance
        sender: Optional custom LLM backend

    Returns:
        dict: Same format as process_text

    Example:
        >>> result = process_audio_file(Path("command.wav"), bridge)
    """
    text = transcribe_audio_file(audio_path)
    if not text:
        return {"status": "error", "error": "Failed to transcribe audio"}

    return process_text(text, bridge, sender=sender)


def process_audio_stream(
    chunks: Iterable[bytes],
    bridge: HttpBridge,
    *,
    sender: Optional[PromptSender] = None
) -> Optional[dict]:
    """
    Transcribe streaming audio chunks (PCM 16kHz mono).

    Args:
        chunks: Iterator of raw PCM audio bytes
        bridge: Bridge instance
        sender: Optional custom LLM backend

    Returns:
        dict: Same format as process_text

    Example:
        >>> chunks = [...]  # From sounddevice recording
        >>> result = process_audio_stream(chunks, bridge)
    """
    text = transcribe_audio_stream(chunks)
    if not text:
        return {"status": "error", "error": "Failed to transcribe audio"}

    return process_text(text, bridge, sender=sender)


def _get_timestamp() -> str:
    """Get current UTC timestamp in ISO 8601 format."""
    from datetime import datetime
    return datetime.utcnow().isoformat() + "Z"
```

**Pipeline Flow**:
```
Audio/Text ‚Üí Transcription ‚Üí Intent ‚Üí Validation ‚Üí Bridge ‚Üí Response
             (Whisper)       (ChatGPT) (schemas)   (HTTP)
```

### 4.2.3 speech.py - Whisper Integration

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Speech-to-text —á–µ—Ä–µ–∑ OpenAI Whisper API

```python
"""Speech-to-text transcription using Whisper."""

import logging
from pathlib import Path
from typing import Iterable, Optional

from .openai_client import get_openai_client

logger = logging.getLogger(__name__)


def transcribe_audio_file(audio_path: Path) -> Optional[str]:
    """
    Transcribe audio file using Whisper API.

    Args:
        audio_path: Path to audio file (WAV, MP3, M4A, etc.)

    Returns:
        str: Transcribed text or None on error

    Supported formats: WAV, MP3, M4A, FLAC, OPUS, WEBM
    Max file size: 25 MB

    Example:
        >>> text = transcribe_audio_file(Path("recording.wav"))
        >>> print(text)  # "–û—Ç–∫—Ä–æ–π –±–ª–æ–∫–Ω–æ—Ç"
    """
    if not audio_path.exists():
        logger.error(f"Audio file not found: {audio_path}")
        return None

    try:
        client = get_openai_client()

        with open(audio_path, 'rb') as audio_file:
            response = client.audio.transcriptions.create(
                model=os.getenv("OPENAI_TRANSCRIPTION_MODEL", "whisper-1"),
                file=audio_file,
                language="ru"  # Russian language hint
            )

        text = response.text.strip()
        logger.info(f"Transcribed audio: {text}")
        return text

    except Exception as exc:
        logger.error(f"Transcription failed: {exc}")
        return None


def transcribe_audio_stream(chunks: Iterable[bytes]) -> Optional[str]:
    """
    Transcribe streaming audio chunks.

    Args:
        chunks: Iterator of raw PCM audio bytes (16kHz, mono, int16)

    Returns:
        str: Transcribed text or None on error

    Note: Concatenates chunks into a WAV file before sending to API.

    Example:
        >>> import sounddevice as sd
        >>> chunks = []
        >>> def callback(indata, frames, time, status):
        ...     chunks.append(bytes(indata))
        >>> with sd.InputStream(callback=callback, samplerate=16000, channels=1):
        ...     time.sleep(5)  # Record 5 seconds
        >>> text = transcribe_audio_stream(chunks)
    """
    try:
        import io
        import wave
        import numpy as np

        # Concatenate chunks
        audio_data = b''.join(chunks)
        audio_array = np.frombuffer(audio_data, dtype=np.int16)

        # Create WAV file in memory
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wav_file:
            wav_file.setnchannels(1)  # Mono
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(16000)
            wav_file.writeframes(audio_array.tobytes())

        wav_buffer.seek(0)
        wav_buffer.name = "recording.wav"  # Required by OpenAI API

        # Transcribe
        client = get_openai_client()
        response = client.audio.transcriptions.create(
            model=os.getenv("OPENAI_TRANSCRIPTION_MODEL", "whisper-1"),
            file=wav_buffer,
            language="ru"
        )

        text = response.text.strip()
        logger.info(f"Transcribed stream: {text}")
        return text

    except Exception as exc:
        logger.error(f"Stream transcription failed: {exc}")
        return None
```

### 4.2.4 nlu.py - Intent Extraction

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —á–µ—Ä–µ–∑ ChatGPT

```python
"""Natural Language Understanding - Intent Extraction."""

import logging
from typing import Optional

from .llm import PromptSender
from .prompts import build_prompt
from .schemas import Command, validate_command

logger = logging.getLogger(__name__)


class IntentExtractor:
    """Extract structured commands from natural language."""

    def __init__(self, sender: Optional[PromptSender] = None):
        """
        Initialize intent extractor.

        Args:
            sender: Optional custom LLM backend (for testing)
        """
        self.sender = sender or PromptSender()

    def extract(self, text: str) -> Optional[Command]:
        """
        Extract command from user text.

        Args:
            text: User's natural language input

        Returns:
            Command object or None if extraction failed

        Example:
            >>> extractor = IntentExtractor()
            >>> cmd = extractor.extract("–æ—Ç–∫—Ä–æ–π –±–ª–æ–∫–Ω–æ—Ç")
            >>> print(cmd.action)  # "open_app"
            >>> print(cmd.params)  # {"application": "notepad"}
        """
        # Build prompt with available applications context
        prompt = build_prompt(text)

        # Send to LLM
        response = self.sender.send_prompt(prompt)

        if not response:
            logger.error("Empty response from LLM")
            return None

        # Parse JSON response
        import json
        try:
            # Extract JSON from response (handle markdown code blocks)
            json_str = response.strip()
            if json_str.startswith("```"):
                # Remove markdown code blocks
                lines = json_str.split("\n")
                json_str = "\n".join(lines[1:-1])

            data = json.loads(json_str)

            # Validate command structure
            if not validate_command(data):
                logger.error(f"Invalid command structure: {data}")
                return None

            # Create Command object
            command = Command(
                action=data["action"],
                params=data.get("params", {}),
                uuid=data.get("uuid", _generate_uuid()),
                timestamp=data.get("timestamp", _get_timestamp())
            )

            logger.info(f"Extracted command: {command.action}")
            return command

        except json.JSONDecodeError as exc:
            logger.error(f"Failed to parse LLM response as JSON: {exc}")
            logger.debug(f"Response was: {response}")
            return None
        except Exception as exc:
            logger.error(f"Command extraction failed: {exc}")
            return None


def _generate_uuid() -> str:
    """Generate random UUID."""
    import uuid
    return str(uuid.uuid4())


def _get_timestamp() -> str:
    """Get current UTC timestamp in ISO 8601 format."""
    from datetime import datetime
    return datetime.utcnow().isoformat() + "Z"
```

### 4.2.5 schemas.py - Command Validation

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã JSON –∫–æ–º–∞–Ω–¥

```python
"""Command schemas and validation."""

from typing import Any, Dict
from dataclasses import dataclass


# Allowed actions and their required parameters
ALLOWED_ACTIONS = {
    "open_app": ["application"],
    "run_exe": ["path"],
    "scan_applications": [],
    "list_applications": [],
    "search_files": ["query"],
    "create_folder": ["path"],
    "delete_folder": ["path"],
    "move_file": ["source", "destination"],
    "copy_file": ["source", "destination"],
    "show_desktop": [],
    "screenshot": [],
    "mute": [],
    "set_volume": ["level"],
    "capture_window": ["application"],
    "record_audio": ["duration"],
    "system_status": [],
    "answer_question": ["answer"]
}


@dataclass
class Command:
    """Structured command object."""
    action: str
    params: Dict[str, Any]
    uuid: str
    timestamp: str

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "action": self.action,
            "params": self.params,
            "uuid": self.uuid,
            "timestamp": self.timestamp
        }


def validate_command(data: dict) -> bool:
    """
    Validate command structure.

    Args:
        data: Command dictionary to validate

    Returns:
        bool: True if valid, False otherwise

    Checks:
        - Has 'action' field
        - Action is in allowed list
        - Has all required parameters
        - Parameters have correct types
    """
    # Check required top-level fields
    if "action" not in data:
        return False

    action = data["action"]

    # Check if action is allowed
    if action not in ALLOWED_ACTIONS:
        return False

    # Check params exist
    params = data.get("params", {})
    if not isinstance(params, dict):
        return False

    # Check required parameters
    required_params = ALLOWED_ACTIONS[action]
    for param in required_params:
        if param not in params:
            return False

    return True
```

### 4.2.6 bridge_requests.py - HTTP Bridge

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: HTTP –∫–ª–∏–µ–Ω—Ç –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å C# Core

```python
"""HTTP bridge to C# Core."""

import logging
from typing import Optional, Dict
import requests

from .schemas import Command

logger = logging.getLogger(__name__)


class HttpBridge:
    """Bridge to C# Core via HTTP."""

    def __init__(self, endpoint: str = "http://localhost:5055"):
        """
        Initialize HTTP bridge.

        Args:
            endpoint: C# Core endpoint URL
        """
        self.endpoint = endpoint.rstrip("/")
        self.timeout = 30  # seconds

    def send_command(self, command: Command) -> Optional[Dict]:
        """
        Send command to C# Core.

        Args:
            command: Command object to send

        Returns:
            dict: Response from C# or None on error
            Format: {"status": "ok"|"error", "result": {...}, "error": str|None}

        Example:
            >>> bridge = HttpBridge("http://localhost:5055")
            >>> cmd = Command(action="system_status", params={}, uuid="test", timestamp="...")
            >>> response = bridge.send_command(cmd)
            >>> print(response["status"])  # "ok"
        """
        url = f"{self.endpoint}/action/execute"

        try:
            response = requests.post(
                url,
                json=command.to_dict(),
                timeout=self.timeout
            )

            response.raise_for_status()
            return response.json()

        except requests.ConnectionError:
            logger.error(f"Failed to connect to C# Core at {self.endpoint}")
            return None
        except requests.Timeout:
            logger.error(f"Request to C# Core timed out after {self.timeout}s")
            return None
        except requests.HTTPError as exc:
            logger.error(f"HTTP error from C# Core: {exc}")
            return None
        except Exception as exc:
            logger.error(f"Unexpected error sending command: {exc}")
            return None

    def get_status(self) -> Optional[Dict]:
        """
        Get C# Core health status.

        Returns:
            dict: Status or None on error

        Example:
            >>> status = bridge.get_status()
            >>> print(status)  # {"status": "ok", "message": "System is operational"}
        """
        url = f"{self.endpoint}/system/status"

        try:
            response = requests.get(url, timeout=5)
            response.raise_for_status()
            return response.json()
        except Exception as exc:
            logger.error(f"Failed to get status: {exc}")
            return None

    def is_available(self) -> bool:
        """
        Check if C# Core is reachable.

        Returns:
            bool: True if available, False otherwise

        Example:
            >>> if bridge.is_available():
            ...     print("C# Core is running")
        """
        status = self.get_status()
        return status is not None and status.get("status") == "ok"
```

### 4.2.7 prompts.py - Prompt Engineering

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –®–∞–±–ª–æ–Ω—ã –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è LLM

```python
"""Prompt templates and helper functions for the LLM."""

import json
import logging
import os
from pathlib import Path
from typing import Iterable, List, Optional

logger = logging.getLogger(__name__)

SYSTEM_PROMPT = (
    "You are an on-device AI assistant for Windows. "
    "You receive spoken or typed requests and must emit a single JSON object. "
    "Follow the C# bridge contract exactly: {action, params, uuid, timestamp}. "
    "When a user names an application, keep that name exactly‚Äîdo not swap it for "
    "a different known app or a store launcher. "
    "Use ISO 8601 timestamps and include only allowed actions: open_app, "
    "search_files, adjust_setting, system_status, answer_question. "
    "When the user asks a question, respond with the answer_question action and "
    "a very concise reply from Aurora, a helpful assistant guiding the user on "
    "how to use the computer."
)

DEFAULT_APPLICATION_HINTS = [
    "notepad", "calculator", "explorer", "paint",
    "chrome", "firefox", "edge",
]


def load_available_applications(
    *, registry_path: Optional[Path] = None, max_items: int = 30
) -> List[str]:
    """
    Load application names/aliases from the registry file.

    Returns:
        List of application names and aliases

    Example:
        >>> apps = load_available_applications()
        >>> print(apps[:5])
        ['notepad', 'calculator', 'chrome', 'discord', 'vscode']
    """
    # Try to load from core/Data/applications.json
    candidates = [
        Path(os.getenv("JARVIS_APP_REGISTRY", "")),
        Path(__file__).parents[2] / "core" / "Data" / "applications.json"
    ]

    for candidate in candidates:
        if not candidate or not candidate.exists():
            continue

        try:
            data = json.loads(candidate.read_text(encoding="utf-8"))
            if not isinstance(data, list):
                continue

            hints = []
            for entry in data:
                name = entry.get("name")
                aliases = entry.get("aliases", [])

                for candidate_name in [name, *aliases]:
                    if isinstance(candidate_name, str):
                        normalized = candidate_name.strip()
                        if normalized and normalized.lower() not in {h.lower() for h in hints}:
                            hints.append(normalized)

            if hints:
                return hints[:max_items]

        except Exception as exc:
            logger.warning(f"Failed to read application registry: {exc}")

    return DEFAULT_APPLICATION_HINTS[:max_items]


def build_prompt(user_message: str, *, available_apps: Optional[Iterable[str]] = None) -> str:
    """
    Compose the final prompt sent to the LLM.

    Args:
        user_message: User's input text
        available_apps: Optional list of known applications

    Returns:
        str: Complete prompt for LLM

    Example:
        >>> prompt = build_prompt("–æ—Ç–∫—Ä–æ–π –±–ª–æ–∫–Ω–æ—Ç")
        >>> print(prompt)
    """
    format_reminder = (
        "Return JSON only, no prose. Include 'action' and 'params' fields. "
        "Example: {\"action\":\"open_app\",\"params\":{\"application\":\"notepad\"}}. "
        "Do NOT include uuid or timestamp - they will be added automatically."
    )

    application_hints = list(available_apps) if available_apps else load_available_applications()
    application_context = ""
    if application_hints:
        formatted_apps = ", ".join(application_hints[:20])
        application_context = (
            "Known applications you can open: "
            f"{formatted_apps}. Prefer these names for open_app commands only when "
            "they match the user's request; never replace the requested app with "
            "a different one just because it is known."
        )

    sections = [SYSTEM_PROMPT, application_context, format_reminder, "", f"User: {user_message}", "Assistant:"]
    return "\n".join([part for part in sections if part])


def build_answer_prompt(user_message: str) -> str:
    """
    Construct a lean prompt to answer general user questions.

    Args:
        user_message: User's question

    Returns:
        str: Prompt for answering question

    Example:
        >>> prompt = build_answer_prompt("–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2 + 2?")
    """
    return "\n".join([
        "You are Aurora, a concise Russian-speaking assistant.",
        "–û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É, –µ—Å–ª–∏ —Ç–µ–±–µ –∑–∞–¥–∞—é—Ç –≤–æ–ø—Ä–æ—Å.",
        "User: " + user_message,
        "Assistant:",
    ])
```

---

## 4.3 C# Core (core/)

### 4.3.1 –û–±–∑–æ—Ä

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: Windows execution engine - –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–∞–Ω–¥

**–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏**:
- C# 11 (.NET 8.0)
- ASP.NET Core 8.0 (Minimal APIs)
- Serilog (logging)
- NAudio (audio recording)
- System.Drawing (screenshots)

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞** (15 —Ñ–∞–π–ª–æ–≤, ~2500 —Å—Ç—Ä–æ–∫):
```
core/
‚îú‚îÄ‚îÄ Program.cs                          # Entry point, HTTP server
‚îú‚îÄ‚îÄ Models/                             # Data models
‚îÇ   ‚îú‚îÄ‚îÄ CommandRequest.cs               # Incoming command
‚îÇ   ‚îú‚îÄ‚îÄ CommandResponse.cs              # Outgoing response
‚îÇ   ‚îî‚îÄ‚îÄ ApplicationInfo.cs              # Application metadata
‚îú‚îÄ‚îÄ Services/                           # Business logic (5 services)
‚îÇ   ‚îú‚îÄ‚îÄ WindowsActionExecutor.cs        # Main dispatcher (1385 lines)
‚îÇ   ‚îú‚îÄ‚îÄ ApplicationScanner.cs           # Scan drives for apps
‚îÇ   ‚îú‚îÄ‚îÄ ApplicationRegistry.cs          # Cache applications
‚îÇ   ‚îú‚îÄ‚îÄ WindowCaptureService.cs         # Screenshot service
‚îÇ   ‚îî‚îÄ‚îÄ MicrophoneRecorder.cs           # Audio recording
‚îú‚îÄ‚îÄ Validation/                         # Security layer
‚îÇ   ‚îú‚îÄ‚îÄ CommandValidator.cs             # Validate actions
‚îÇ   ‚îî‚îÄ‚îÄ PathValidator.cs                # Path security
‚îú‚îÄ‚îÄ Security/                           # Additional security
‚îÇ   ‚îî‚îÄ‚îÄ RateLimiter.cs                  # Rate limiting
‚îú‚îÄ‚îÄ Data/                               # Application registry
‚îÇ   ‚îî‚îÄ‚îÄ applications.json               # Cached apps
‚îú‚îÄ‚îÄ appsettings.json                    # Configuration
‚îî‚îÄ‚îÄ JarvisCore.csproj                   # Project file
```

### 4.3.2 Program.cs - Entry Point

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: HTTP server setup, dependency injection

```csharp
using Microsoft.AspNetCore.Builder;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;
using Serilog;
using JarvisCore.Services;
using JarvisCore.Validation;

var builder = WebApplication.CreateBuilder(args);

// Configure Serilog
Log.Logger = new LoggerConfiguration()
    .WriteTo.Console()
    .WriteTo.File("logs/jarvis-.txt", rollingInterval: RollingInterval.Day)
    .CreateLogger();

builder.Host.UseSerilog();

// Add services to DI container
builder.Services.AddControllers();
builder.Services.AddSingleton<WindowsActionExecutor>();
builder.Services.AddSingleton<ApplicationScanner>();
builder.Services.AddSingleton<ApplicationRegistry>();
builder.Services.AddSingleton<WindowCaptureService>();
builder.Services.AddSingleton<MicrophoneRecorder>();
builder.Services.AddSingleton<CommandValidator>();

var app = builder.Build();

// Configure HTTP pipeline
app.UseCors(policy => policy.AllowAnyOrigin().AllowAnyMethod().AllowAnyHeader());

// Main endpoint: POST /action/execute
app.MapPost("/action/execute", async (
    CommandRequest request,
    WindowsActionExecutor executor,
    CommandValidator validator) =>
{
    // Validate command
    var validationError = validator.Validate(request);
    if (validationError != null)
    {
        return Results.BadRequest(new CommandResponse
        {
            Status = "error",
            Error = validationError
        });
    }

    // Execute command
    var response = await executor.ExecuteAsync(request);
    return Results.Ok(response);
});

// Health check endpoint: GET /system/status
app.MapGet("/system/status", () =>
{
    return Results.Ok(new
    {
        status = "ok",
        message = "System is operational",
        version = "1.0.0"
    });
});

app.Run();
```

### 4.3.3 WindowsActionExecutor.cs - Action Dispatcher

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –ì–ª–∞–≤–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä –∫–æ–º–∞–Ω–¥ - –Ω–∞–ø—Ä–∞–≤–ª—è–µ—Ç action –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥

**–ö–ª—é—á–µ–≤—ã–µ –ú–µ—Ç–æ–¥—ã**:

```csharp
public class WindowsActionExecutor
{
    private readonly ILogger<WindowsActionExecutor> _logger;
    private readonly ApplicationRegistry _registry;
    private readonly WindowCaptureService _captureService;
    private readonly MicrophoneRecorder _recorder;

    public async Task<CommandResponse> ExecuteAsync(CommandRequest request)
    {
        _logger.LogInformation("Executing action: {Action}", request.Action);

        return request.Action switch
        {
            // Application management
            "open_app" => await OpenApplication(request),
            "run_exe" => await RunExecutable(request),
            "scan_applications" => await ScanApplications(request),
            "list_applications" => await ListApplications(request),

            // File system
            "search_files" => await SearchFiles(request),
            "create_folder" => await CreateFolder(request),
            "delete_folder" => await DeleteFolder(request),
            "move_file" => await MoveFile(request),
            "copy_file" => await CopyFile(request),

            // System control
            "show_desktop" => ShowDesktop(request),
            "screenshot" => await CaptureScreenshot(request),
            "mute" => ToggleMute(request),
            "set_volume" => SetVolume(request),

            // Advanced
            "capture_window" => await CaptureWindow(request),
            "record_audio" => await RecordAudio(request),
            "system_status" => GetSystemStatus(request),
            "answer_question" => AnswerQuestion(request),

            _ => new CommandResponse
            {
                Status = "error",
                Error = $"Unknown action: {request.Action}"
            }
        };
    }

    // Example: OpenApplication
    private async Task<CommandResponse> OpenApplication(CommandRequest request)
    {
        var appName = request.Params["application"]?.ToString();
        if (string.IsNullOrWhiteSpace(appName))
        {
            return new CommandResponse
            {
                Status = "error",
                Error = "Missing 'application' parameter"
            };
        }

        // Find in registry
        var appInfo = _registry.FindApplication(appName);
        if (appInfo == null)
        {
            return new CommandResponse
            {
                Status = "error",
                Error = $"Application '{appName}' not found in registry. Try running 'scan_applications' first."
            };
        }

        try
        {
            var startInfo = new ProcessStartInfo
            {
                FileName = appInfo.Path,
                UseShellExecute = true,
                // IMPORTANT: Set working directory to app's directory
                WorkingDirectory = Path.GetDirectoryName(appInfo.Path) ?? Environment.CurrentDirectory
            };

            var process = Process.Start(startInfo);

            return new CommandResponse
            {
                Status = "ok",
                Result = new
                {
                    application = appInfo.Name,
                    path = appInfo.Path,
                    category = appInfo.Category,
                    processId = process?.Id,
                    message = $"Successfully opened {appInfo.Name}"
                }
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to open application: {AppName}", appName);
            return new CommandResponse
            {
                Status = "error",
                Error = $"Failed to open application: {ex.Message}"
            };
        }
    }

    // Example: Screenshot
    private async Task<CommandResponse> CaptureScreenshot(CommandRequest request)
    {
        try
        {
            // Capture screen
            var screenshot = CaptureScreen();

            // Save to file
            var fileName = $"screenshot_{DateTime.Now:yyyyMMdd_HHmmss}.png";
            var savePath = Path.Combine(
                Environment.GetFolderPath(Environment.SpecialFolder.MyPictures),
                fileName
            );

            screenshot.Save(savePath, ImageFormat.Png);

            // Convert to Base64
            using var ms = new MemoryStream();
            screenshot.Save(ms, ImageFormat.Png);
            var base64 = Convert.ToBase64String(ms.ToArray());

            return new CommandResponse
            {
                Status = "ok",
                Result = new
                {
                    path = savePath,
                    image = base64,
                    message = $"Screenshot saved to {savePath}"
                }
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to capture screenshot");
            return new CommandResponse
            {
                Status = "error",
                Error = $"Failed to capture screenshot: {ex.Message}"
            };
        }
    }

    private Bitmap CaptureScreen()
    {
        var bounds = Screen.PrimaryScreen.Bounds;
        var bitmap = new Bitmap(bounds.Width, bounds.Height);

        using var graphics = Graphics.FromImage(bitmap);
        graphics.CopyFromScreen(Point.Empty, Point.Empty, bounds.Size);

        return bitmap;
    }

    // Example: Set Volume
    private CommandResponse SetVolume(CommandRequest request)
    {
        var level = Convert.ToInt32(request.Params["level"]);

        if (level < 0 || level > 100)
        {
            return new CommandResponse
            {
                Status = "error",
                Error = "Volume level must be between 0 and 100"
            };
        }

        try
        {
            // Use CoreAudioApi to set volume
            var deviceEnumerator = new MMDeviceEnumerator();
            var device = deviceEnumerator.GetDefaultAudioEndpoint(DataFlow.Render, Role.Multimedia);
            device.AudioEndpointVolume.MasterVolumeLevelScalar = level / 100f;

            return new CommandResponse
            {
                Status = "ok",
                Result = new
                {
                    level = level,
                    message = $"Volume set to {level}%"
                }
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to set volume");
            return new CommandResponse
            {
                Status = "error",
                Error = $"Failed to set volume: {ex.Message}"
            };
        }
    }
}
```

### 4.3.4 ApplicationScanner.cs - Application Discovery

**–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ**: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –¥–∏—Å–∫–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π

**–°–∫–∞–Ω–∏—Ä—É–µ–º—ã–µ Locations**:
- `C:\Program Files`
- `C:\Program Files (x86)`
- `%LOCALAPPDATA%\Programs`
- `%LOCALAPPDATA%\Discord`, `%LOCALAPPDATA%\Microsoft\WindowsApps`
- `%APPDATA%\Telegram Desktop`, `%APPDATA%\Spotify`
- Steam libraries (auto-detect via `libraryfolders.vdf`)
- Epic Games, GOG Games, Riot Games
- –í—Å–µ –¥–∏—Å–∫–∏ (C:, D:, E:, ...)

**–ê–ª–≥–æ—Ä–∏—Ç–º**:
1. Recursively scan directories for .exe files
2. Skip system folders (Windows, System32)
3. Extract metadata (name, version, icon)
4. Categorize applications (Games, Communication, Development, etc.)
5. Generate Russian aliases
6. Save to `core/Data/applications.json`

**Performance**: ~30-60 seconds –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è

---

# 5. API Reference

## 5.1 C# HTTP API

**Base URL**: `http://localhost:5055`

**Endpoint**: `POST /action/execute`

**Request Format**:
```json
{
  "action": "action_name",
  "params": {
    "param1": "value1",
    "param2": "value2"
  },
  "uuid": "unique-id",
  "timestamp": "2025-12-27T10:00:00Z"
}
```

**Response Format**:
```json
{
  "status": "ok" | "error",
  "result": { ... } | null,
  "error": "error message" | null
}
```

---

## 5.1.1 open_app - Open Application

**Description**: Opens a Windows application by name or alias

**Parameters**:
- `application` (string, required): Application name or alias

**Example Request**:
```json
{
  "action": "open_app",
  "params": {
    "application": "chrome"
  },
  "uuid": "550e8400-e29b-41d4-a716-446655440000",
  "timestamp": "2025-12-27T10:30:00Z"
}
```

**Success Response**:
```json
{
  "status": "ok",
  "result": {
    "application": "Google Chrome",
    "path": "C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe",
    "category": "Browser",
    "processId": 12345,
    "message": "Successfully opened Google Chrome"
  },
  "error": null
}
```

**Error Response**:
```json
{
  "status": "error",
  "result": null,
  "error": "Application 'unknownapp' not found in registry. Try running 'scan_applications' first."
}
```

**cURL Example**:
```bash
curl -X POST http://localhost:5055/action/execute \
  -H "Content-Type: application/json" \
  -d '{
    "action": "open_app",
    "params": {"application": "chrome"},
    "uuid": "test-123",
    "timestamp": "2025-12-27T10:30:00Z"
  }'
```

**Python Example**:
```python
import requests

response = requests.post('http://localhost:5055/action/execute', json={
    'action': 'open_app',
    'params': {'application': 'chrome'},
    'uuid': 'test-123',
    'timestamp': '2025-12-27T10:30:00Z'
})
print(response.json())
```

**JavaScript Example**:
```javascript
const response = await fetch('http://localhost:5055/action/execute', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    action: 'open_app',
    params: { application: 'chrome' },
    uuid: 'test-123',
    timestamp: new Date().toISOString()
  })
});
const data = await response.json();
console.log(data);
```

## 5.1.2 screenshot - Capture Screen

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**: –ù–µ—Ç

**–ü—Ä–∏–º–µ—Ä—ã –∫–æ–º–∞–Ω–¥**:
- "—Å–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç"
- "take a screenshot"

**Request**:
```json
{"action": "screenshot", "params": {}, "uuid": "...", "timestamp": "..."}
```

**Response**:
```json
{
  "status": "ok",
  "result": {
    "path": "C:\\Users\\...\\Pictures\\screenshot_20251227_103000.png",
    "image": "base64_string_here...",
    "message": "Screenshot saved to ..."
  }
}
```

## 5.1.3 set_volume - Set System Volume

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**:
- `level` (integer, required): 0-100

**–ü—Ä–∏–º–µ—Ä—ã**: "–≥—Ä–æ–º–∫–æ—Å—Ç—å 50", "volume 80"

**Request**:
```json
{"action": "set_volume", "params": {"level": 50}, "uuid": "...", "timestamp": "..."}
```

**Response**:
```json
{"status": "ok", "result": {"level": 50, "message": "Volume set to 50%"}}
```

## 5.1.4 scan_applications - Scan for Apps

**–û–ø–∏—Å–∞–Ω–∏–µ**: –°–∫–∞–Ω–∏—Ä—É–µ—Ç –≤—Å–µ –¥–∏—Å–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã**: –ù–µ—Ç

**–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è**: 30-60 —Å–µ–∫—É–Ω–¥

**Request**:
```json
{"action": "scan_applications", "params": {}, "uuid": "...", "timestamp": "..."}
```

**Response**:
```json
{
  "status": "ok",
  "result": {
    "found": 127,
    "categories": {"Games": 45, "Communication": 12, "Development": 18, "Browser": 8, "Other": 44},
    "message": "Found 127 applications"
  }
}
```

## 5.1.5 –û—Å—Ç–∞–ª—å–Ω—ã–µ –ö–æ–º–∞–Ω–¥—ã (–ö—Ä–∞—Ç–∫–∏–π –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫)

| Action | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã | –û–ø–∏—Å–∞–Ω–∏–µ |
|--------|-----------|----------|
| **run_exe** | `path` (string) | –ó–∞–ø—É—Å–∫ .exe —Ñ–∞–π–ª–∞ –ø–æ –ø—É—Ç–∏ |
| **list_applications** | `category` (optional) | –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π |
| **search_files** | `query` (string) | –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ Documents/Desktop |
| **create_folder** | `path` (string) | –°–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É |
| **delete_folder** | `path` (string) | –£–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É |
| **move_file** | `source`, `destination` | –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Ñ–∞–π–ª |
| **copy_file** | `source`, `destination` | –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª |
| **show_desktop** | - | –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª (Win+D) |
| **mute** | - | –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å mute |
| **capture_window** | `application` (string) | –°–∫—Ä–∏–Ω—à–æ—Ç –æ–∫–Ω–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è |
| **record_audio** | `duration` (number), `fileName` (optional) | –ó–∞–ø–∏—Å–∞—Ç—å –∞—É–¥–∏–æ —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ |
| **system_status** | - | –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ |
| **answer_question** | `answer` (string), `question` (optional) | –û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ TTS |

---

# 6. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

## 6.1 Environment Variables (.env)

–§–∞–π–ª: `ai-python/.env`

```env
# –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
OPENAI_API_KEY=sk-proj-YOUR_KEY_HERE

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û - OpenAI Settings
OPENAI_MODEL=gpt-4o-mini                    # Chat model: gpt-4, gpt-4o-mini, gpt-3.5-turbo
OPENAI_TRANSCRIPTION_MODEL=whisper-1        # Transcription model
OPENAI_BASE_URL=https://api.openai.com/v1   # Custom endpoint (–¥–ª—è Azure –∏–ª–∏ custom)
OPENAI_TRANSCRIPTION_LANGUAGE_HINT=ru       # Language hint: ru, en

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û - Proxy
OPENAI_PROXY=http://user:pass@host:port     # HTTP proxy

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û - Endpoints
JARVIS_CORE_ENDPOINT=http://localhost:5055  # C# Core URL
JARVIS_APP_REGISTRY=/path/to/applications.json  # Custom app registry path

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û - Audio
MIC_SILENCE_THRESHOLD=200                   # Silence detection (50-1000, lower = more sensitive)

# –û–ü–¶–ò–û–ù–ê–õ–¨–ù–û - Wake Word
WHISPER_MODEL=base                          # Whisper model: tiny, base, small, medium, large
```

## 6.2 C# Configuration (appsettings.json)

–§–∞–π–ª: `core/appsettings.json`

```json
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning"
    }
  },
  "AllowedHosts": "*",
  "Kestrel": {
    "Endpoints": {
      "Http": {
        "Url": "http://localhost:5055"
      }
    }
  }
}
```

**–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞**:
```json
"Http": { "Url": "http://localhost:6000" }
```

## 6.3 Electron Configuration

–§–∞–π–ª: `%APPDATA%/Roaming/ayvor-config.json` (—Å–æ–∑–¥–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)

```json
{
  "coreEndpoint": "http://localhost:5055",
  "openaiKey": "sk-...",
  "language": "ru-RU",
  "hotkey": "CommandOrControl+Shift+Space",
  "microphoneDeviceId": "default",
  "silenceThreshold": 200,
  "noiseSuppression": true,
  "autoGainControl": true,
  "wakeWordEnabled": true
}
```

–£–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ Settings UI –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏.

## 6.4 Wake Word Model Configuration

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
export WHISPER_MODEL=base    # Windows: set WHISPER_MODEL=base
python wake_word.py
```

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π**:
| Model | Size | Latency | Accuracy | RAM | –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è |
|-------|------|---------|----------|-----|--------------|
| tiny | 39 MB | ~200ms | 70% | 1 GB | ‚ùå –ù–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å |
| base | 74 MB | ~400ms | 85% | 1 GB | ‚úÖ **–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é** |
| small | 244 MB | ~800ms | 90% | 2 GB | ‚úÖ –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| medium | 769 MB | ~2s | 95% | 5 GB | ‚ö†Ô∏è –ú–µ–¥–ª–µ–Ω–Ω–æ |
| large | 2.9 GB | ~5s | 98% | 10 GB | ‚ùå –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ |

---

# 7. –ö–æ–º–∞–Ω–¥—ã

## 7.1 –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏

### –û—Ç–∫—Ä—ã—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
**–†—É—Å—Å–∫–∏–π**: "–ê–≤—Ä–æ—Ä–∞, –æ—Ç–∫—Ä–æ–π Chrome", "–∑–∞–ø—É—Å—Ç–∏ Discord", "–≤–∫–ª—é—á–∏ –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä"
**English**: "Aurora, open Chrome", "launch Discord", "start calculator"
**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è**: notepad, calculator, chrome, firefox, edge, discord, telegram, spotify, vscode, pycharm, –∏ 100+ –¥—Ä—É–≥–∏—Ö

### –ó–∞–ø—É—Å—Ç–∏—Ç—å exe —Ñ–∞–π–ª
**–†—É—Å—Å–∫–∏–π**: "–ó–∞–ø—É—Å—Ç–∏ C:\\Apps\\tool.exe"
**English**: "Run C:\\Apps\\tool.exe"
**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è**: –¢–æ–ª—å–∫–æ .exe —Ñ–∞–π–ª—ã, –ø—É—Ç—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–Ω—ã–º

### –°–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
**–†—É—Å—Å–∫–∏–π**: "–ü—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è", "–Ω–∞–π–¥–∏ –≤—Å–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã"
**English**: "Scan applications", "find all programs"
**–í—Ä–µ–º—è**: 30-60 —Å–µ–∫—É–Ω–¥

## 7.2 –§–∞–π–ª–æ–≤–∞—è –°–∏—Å—Ç–µ–º–∞

### –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
**–†—É—Å—Å–∫–∏–π**: "–ù–∞–π–¥–∏ —Ñ–∞–π–ª –æ—Ç—á–µ—Ç", "–Ω–∞–π–¥–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é"
**English**: "Search for report", "find presentation"
**–ì–¥–µ –∏—â–µ—Ç**: Documents, Desktop

### –°–æ–∑–¥–∞—Ç—å –ø–∞–ø–∫—É
**–†—É—Å—Å–∫–∏–π**: "–°–æ–∑–¥–∞–π –ø–∞–ø–∫—É Projects", "—Å–æ–∑–¥–∞–π –ø–∞–ø–∫—É C:\\Work"
**English**: "Create folder Projects"

### –£–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É
**–†—É—Å—Å–∫–∏–π**: "–£–¥–∞–ª–∏ –ø–∞–ø–∫—É Temp"
**English**: "Delete folder Temp"
**‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ**: –£–¥–∞–ª—è–µ—Ç —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ!

## 7.3 –°–∏—Å—Ç–µ–º–Ω–æ–µ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ

### –°–∫—Ä–∏–Ω—à–æ—Ç
**–†—É—Å—Å–∫–∏–π**: "–°–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç", "—Å–∫—Ä–∏–Ω", "—Å—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—Ä—É–π —ç–∫—Ä–∞–Ω"
**English**: "Take a screenshot", "capture screen"
**–°–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è**: `%USERPROFILE%\Pictures\screenshot_YYYYMMDD_HHmmss.png`

### –ì—Ä–æ–º–∫–æ—Å—Ç—å
**–†—É—Å—Å–∫–∏–π**: "–ì—Ä–æ–º–∫–æ—Å—Ç—å 50", "–≥—Ä–æ–º–∫–æ—Å—Ç—å –Ω–∞ –º–∞–∫—Å–∏–º—É–º", "–≥—Ä–æ–º–∫–æ—Å—Ç—å 0"
**English**: "Volume 50", "volume max", "volume 0"
**–î–∏–∞–ø–∞–∑–æ–Ω**: 0-100

### –ü–æ–∫–∞–∑–∞—Ç—å —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª
**–†—É—Å—Å–∫–∏–π**: "–ü–æ–∫–∞–∂–∏ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª", "—Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª"
**English**: "Show desktop"
**–î–µ–π—Å—Ç–≤–∏–µ**: Win+D (—Å–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ –æ–∫–Ω–∞)

### Mute
**–†—É—Å—Å–∫–∏–π**: "–í—ã–∫–ª—é—á–∏ –∑–≤—É–∫", "–±–µ–∑ –∑–≤—É–∫–∞", "mute"
**English**: "Mute", "silence"
**–î–µ–π—Å—Ç–≤–∏–µ**: Toggle mute

## 7.4 –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–µ –ö–æ–º–∞–Ω–¥—ã

### –í–æ–ø—Ä–æ—Å—ã
**–†—É—Å—Å–∫–∏–π**: "–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 5 + 3?", "–ß—Ç–æ —Ç–∞–∫–æ–µ Python?", "–ö–∞–∫ –æ—Ç–∫—Ä—ã—Ç—å Task Manager?"
**English**: "What is 5 + 3?", "What is Python?", "How to open Task Manager?"
**–û—Ç–≤–µ—Ç**: –ß–µ—Ä–µ–∑ ChatGPT + voice synthesis

---

# 8. –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞

## 8.1 Project Structure

```
AIYandexStartup_Assistent/
‚îú‚îÄ‚îÄ ai-python/                 # Python AI layer
‚îÇ   ‚îú‚îÄ‚îÄ ai_assistant/          # Core package (10 modules, 974 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py        # Orchestration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nlu.py             # Intent extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ speech.py          # Whisper STT
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py             # ChatGPT backends
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bridge_requests.py # HTTP bridge
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py         # Validation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py         # Prompt templates
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai_client.py   # OpenAI client
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Demo entry point
‚îÇ   ‚îú‚îÄ‚îÄ test_connection.py     # Bridge test
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt       # Dependencies
‚îÇ
‚îú‚îÄ‚îÄ core/                      # C# execution engine
‚îÇ   ‚îú‚îÄ‚îÄ Models/                # Data models
‚îÇ   ‚îú‚îÄ‚îÄ Services/              # Business logic (5 services)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WindowsActionExecutor.cs    # Main dispatcher (1385 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ApplicationScanner.cs       # Scan drives
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ApplicationRegistry.cs      # Cache apps
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ WindowCaptureService.cs     # Screenshots
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MicrophoneRecorder.cs       # Audio recording
‚îÇ   ‚îú‚îÄ‚îÄ Validation/            # Security layer
‚îÇ   ‚îú‚îÄ‚îÄ Program.cs             # Entry point
‚îÇ   ‚îî‚îÄ‚îÄ appsettings.json       # Config
‚îÇ
‚îú‚îÄ‚îÄ jarvis-gui/                # Electron desktop app
‚îÇ   ‚îú‚îÄ‚îÄ main.js                # Main process (543 lines)
‚îÇ   ‚îú‚îÄ‚îÄ renderer.js            # UI logic (1235 lines)
‚îÇ   ‚îú‚îÄ‚îÄ preload.js             # IPC bridge (115 lines)
‚îÇ   ‚îú‚îÄ‚îÄ wake_word.py           # Wake word detection (186 lines)
‚îÇ   ‚îú‚îÄ‚îÄ index.html             # UI structure
‚îÇ   ‚îî‚îÄ‚îÄ styles.css             # Styling
‚îÇ
‚îî‚îÄ‚îÄ docs/                      # Documentation
    ‚îî‚îÄ‚îÄ FULL-DOCUMENTATION.md  # This file
```

## 8.2 Adding New Commands

### –®–∞–≥ 1: –î–æ–±–∞–≤–∏—Ç—å –≤ C# CommandValidator

```csharp
// Validation/CommandValidator.cs
private static readonly HashSet<string> _allowedActions = new()
{
    // ... existing
    "my_new_action"
};

private static readonly Dictionary<string, string[]> _requiredParams = new()
{
    // ... existing
    ["my_new_action"] = new[] { "param1", "param2" }
};
```

### –®–∞–≥ 2: –î–æ–±–∞–≤–∏—Ç—å handler –≤ WindowsActionExecutor

```csharp
// Services/WindowsActionExecutor.cs
public async Task<CommandResponse> ExecuteAsync(CommandRequest request)
{
    return request.Action switch
    {
        // ... existing
        "my_new_action" => await MyNewAction(request),
        _ => new CommandResponse { Status = "error", Error = $"Unknown action: {request.Action}" }
    };
}

private async Task<CommandResponse> MyNewAction(CommandRequest request)
{
    var param1 = request.Params["param1"]?.ToString();

    try
    {
        // Your code here
        var result = DoSomething(param1);

        return new CommandResponse
        {
            Status = "ok",
            Result = new { param1, result },
            Error = null
        };
    }
    catch (Exception ex)
    {
        _logger.LogError(ex, "Failed my_new_action");
        return new CommandResponse { Status = "error", Error = ex.Message };
    }
}
```

### –®–∞–≥ 3: –î–æ–±–∞–≤–∏—Ç—å –≤ Python schemas.py

```python
# ai-python/ai_assistant/schemas.py
ALLOWED_ACTIONS = {
    # ... existing
    "my_new_action": ["param1", "param2"],
}
```

### –®–∞–≥ 4: –û–±–Ω–æ–≤–∏—Ç—å prompt (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```python
# ai-python/ai_assistant/prompts.py
SYSTEM_PROMPT = (
    "... allowed actions: open_app, ..., my_new_action. ..."
)
```

## 8.3 Testing

### Python Tests
```bash
cd ai-python
pytest                          # All tests
pytest tests/test_nlu.py        # Specific module
pytest -v                       # Verbose
```

### Manual Testing
```bash
# Terminal 1: C# Core
cd core
dotnet run

# Terminal 2: Test command
curl -X POST http://localhost:5055/action/execute \
  -H "Content-Type: application/json" \
  -d '{"action":"my_new_action","params":{"param1":"test"},"uuid":"test","timestamp":"2025-12-27T10:00:00Z"}'
```

## 8.4 Build & Package

### C# Core (Production)
```bash
cd core
dotnet publish -c Release -o publish/
# Output: publish/JarvisCore.exe
```

### Electron GUI (Windows Installer)
```bash
cd jarvis-gui
npm run build
# Output: dist/Ayvor Setup 1.0.0.exe
```

---

# 9. –ü—Ä–∏–º–µ—Ä—ã –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

## 9.1 Python Script Example

```python
#!/usr/bin/env python3
"""Automation script using AYVOR."""

from ai_assistant.pipeline import process_text
from ai_assistant.bridge_requests import HttpBridge

def main():
    bridge = HttpBridge("http://localhost:5055")

    if not bridge.is_available():
        print("ERROR: C# core not running!")
        return

    commands = [
        "–æ—Ç–∫—Ä–æ–π –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä",
        "–≥—Ä–æ–º–∫–æ—Å—Ç—å 30",
        "—Å–¥–µ–ª–∞–π —Å–∫—Ä–∏–Ω—à–æ—Ç"
    ]

    for cmd in commands:
        print(f"\nExecuting: {cmd}")
        result = process_text(cmd, bridge)

        if result['status'] == 'ok':
            print(f"‚úÖ Success: {result['result']['message']}")
        else:
            print(f"‚ùå Error: {result['error']}")

if __name__ == "__main__":
    main()
```

## 9.2 Morning Routine Script

```python
from time import sleep
from ai_assistant.bridge_requests import HttpBridge
from ai_assistant.schemas import Command
from datetime import datetime

bridge = HttpBridge("http://localhost:5055")

def morning_routine():
    """Open all apps for morning work."""
    apps = ["chrome", "discord", "telegram", "spotify", "vscode"]

    for app in apps:
        cmd = Command(
            action="open_app",
            params={"application": app},
            uuid=f"morning-{app}",
            timestamp=datetime.utcnow().isoformat() + "Z"
        )
        result = bridge.send_command(cmd)
        print(f"Opened {app}: {result['status']}")
        sleep(2)

    # Set volume
    bridge.send_command(Command(
        action="set_volume",
        params={"level": 50},
        uuid="morning-volume",
        timestamp=datetime.utcnow().isoformat() + "Z"
    ))

morning_routine()
```

## 9.3 Direct HTTP API Usage

```python
import requests

def send_command(action, params):
    response = requests.post('http://localhost:5055/action/execute', json={
        'action': action,
        'params': params,
        'uuid': 'script-001',
        'timestamp': '2025-12-27T10:30:00Z'
    })
    return response.json()

# Examples
result = send_command('open_app', {'application': 'notepad'})
print(result)

result = send_command('screenshot', {})
import base64
with open('screenshot.png', 'wb') as f:
    f.write(base64.b64decode(result['result']['image']))
```

---

# 10. –†–µ—à–µ–Ω–∏–µ –ü—Ä–æ–±–ª–µ–º

## 10.1 –ß–∞—Å—Ç—ã–µ –û—à–∏–±–∫–∏

### "OpenAI API authentication failed"
**–ü—Ä–∏—á–∏–Ω–∞**: –ù–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á
**–†–µ—à–µ–Ω–∏–µ**:
1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ `ai-python/.env`
2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ `OPENAI_API_KEY` —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ [platform.openai.com](https://platform.openai.com)

### "Port 5055 already in use"
**–ü—Ä–∏—á–∏–Ω–∞**: –î—Ä—É–≥–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ—Ä—Ç
**–†–µ—à–µ–Ω–∏–µ**:
```bash
netstat -ano | findstr :5055
taskkill /PID <PID> /F
```
–ò–ª–∏ –∏–∑–º–µ–Ω–∏—Ç–µ –ø–æ—Ä—Ç –≤ `core/appsettings.json`

### "Wake word not detecting"
**–ü—Ä–∏—á–∏–Ω–∞**: –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
**–†–µ—à–µ–Ω–∏–µ**:
```python
import sounddevice as sd
print(sd.query_devices())  # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω
```
–ü–µ—Ä–µ–∫–ª—é—á–∏—Ç–µ –º–æ–¥–µ–ª—å:
```bash
export WHISPER_MODEL=small
python wake_word.py
```

### "Application not found"
**–ü—Ä–∏—á–∏–Ω–∞**: –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –≤ registry
**–†–µ—à–µ–Ω–∏–µ**: –ó–∞–ø—É—Å—Ç–∏—Ç–µ `"–ø—Ä–æ—Å–∫–∞–Ω–∏—Ä—É–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"` –∏–ª–∏ —á–µ—Ä–µ–∑ API:
```bash
curl -X POST http://localhost:5055/action/execute \
  -d '{"action":"scan_applications","params":{},"uuid":"scan","timestamp":"2025-12-27T10:00:00Z"}'
```

## 10.2 Performance Optimization

**Tip 1**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ base –º–æ–¥–µ–ª—å –¥–ª—è wake word (–Ω–µ medium/large)
**Tip 2**: –ö—ç—à–∏—Ä—É–π—Ç–µ application registry (–Ω–µ —Å–∫–∞–Ω–∏—Ä—É–π—Ç–µ –∫–∞–∂–¥—ã–π —Ä–∞–∑)
**Tip 3**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ gpt-3.5-turbo –≤–º–µ—Å—Ç–æ gpt-4 –¥–ª—è faster responses

---

# 11. –ò—Å—Ç–æ—Ä–∏—è –ò–∑–º–µ–Ω–µ–Ω–∏–π

## [1.0.0] - 2025-12-27

### Added
- ‚úÖ Wake word detection using Whisper AI (–∑–∞–º–µ–Ω–∏–ª Vosk, 95% accuracy)
- ‚úÖ 15 —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ (–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, —Ñ–∞–π–ª—ã, —Å–∏—Å—Ç–µ–º–∞)
- ‚úÖ Application scanner —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º (100+ apps)
- ‚úÖ Electron Desktop GUI —Å cyberpunk –¥–∏–∑–∞–π–Ω–æ–º
- ‚úÖ HTTP bridge –º–µ–∂–¥—É Python –∏ C#
- ‚úÖ Command validation –∏ security (path validation, rate limiting)
- ‚úÖ Logging —á–µ—Ä–µ–∑ Serilog
- ‚úÖ System tray integration
- ‚úÖ Global hotkey (Ctrl+Shift+Space)
- ‚úÖ Voice feedback —á–µ—Ä–µ–∑ Speech Synthesis API
- ‚úÖ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–æ–≤
- ‚úÖ WorkingDirectory fix –¥–ª—è Discord –∏ –¥—Ä—É–≥–∏—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π

### Changed
- –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–ª–∏ wake word —Å "–ê–π–≤–æ—Ä" –Ω–∞ "–ê–≤—Ä–æ—Ä–∞"
- –£–ª—É—á—à–µ–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å wake word detection (~95% vs 70-80% —É Vosk)

### Fixed
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ Discord (–¥–æ–±–∞–≤–ª–µ–Ω WorkingDirectory)
- Proxy –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –¥–ª—è OpenAI API

---

**–ö–æ–Ω–µ—Ü –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏**

**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025-12-27
**–í–µ—Ä—Å–∏—è**: 1.0.0
**–°—Ç–∞—Ç—É—Å**: Production Ready (58% complete)
**–°—Ç—Ä–∞–Ω–∏—Ü**: ~100+
**–°—Ç—Ä–æ–∫ –∫–æ–¥–∞**: ~2700+ (Python), ~2500+ (C#), ~2000+ (JavaScript)
